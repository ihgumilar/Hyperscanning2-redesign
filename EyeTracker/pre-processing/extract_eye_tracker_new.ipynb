{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import packages\n",
    "import chunk\n",
    "import mne\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "import numbers\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract baseline of eye tracker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Extract baseline data\n",
    "\n",
    "def extract_baseline_eye_data(path_2_csv_files: str, path_2_save_baseline_file: str, labelsequence: int =1, bad_files: list =[]):\n",
    "    \"\"\" \n",
    "    Extract baseline data from raw Eye Tracker file (*.csv) that was obtained from hyperscanning2-redesign experiment \\n\n",
    "\n",
    "    Arguments :\n",
    "        - path_2_csv_files (str) : path to raw Eye tracker file \\n\n",
    "        - path_2_save_baseline_file (str) : path to save extracted baseline file for each condition \\n\n",
    "        - labelsequence (int) : order of pre-defined label sequence, 1 (averted) is default \\n\n",
    "        - bad_files (list) (optional) : file name of raw EyeTracker file, e.g., EyeTracker-S8.csv, that wants to be skipped to process\n",
    "\n",
    "    Return :\n",
    "        Extracted *.csv file for each condition of hand (finger pointing and tracking). \n",
    "        There are 6 files in total for each participant.\n",
    "    \"\"\"\n",
    "\n",
    "    ## Temporary\n",
    "    # path_2_csv_files = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/\"\n",
    "    # path_2_save_baseline_file = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/raw_baseline_eye_data/\"\n",
    "    # labelsequence = 1\n",
    "    # bad_files=[]\n",
    "\n",
    "    ### \n",
    "\n",
    "    list_file_names = []\n",
    "    full_path_2_each_file = []\n",
    "   \n",
    "    for file in os.listdir(path_2_csv_files):\n",
    "\n",
    "        if file.endswith(\".csv\"):\n",
    "\n",
    "            if (file in bad_files):\n",
    "                # Skip the bad file to be processed\n",
    "                print(f\"Skipped bad file : {file}\")\n",
    "                continue\n",
    "\n",
    "            # Populate all file names only\n",
    "            list_file_names.append(file)\n",
    "            list_file_names.sort()\n",
    "\n",
    "\n",
    "        # Iterate all file names\n",
    "\n",
    "        for i in tqdm(range(len(list_file_names)), desc=\"In progress\"):\n",
    "            \n",
    "\n",
    "            try:\n",
    "                labelsequence = int(labelsequence)\n",
    "\n",
    "            except IOError as err_filename:\n",
    "                print(\"The format of file name is not correct or file doesn't exist \\nThe format must be 'EEG-Sx.csv' , x=subject number \")\n",
    "                raise\n",
    "            except ValueError as err_integer:\n",
    "                print(\"The labelsequence input must be integer : \", err_integer)\n",
    "                raise\n",
    "\n",
    "            else:\n",
    "                if  labelsequence < 1 or labelsequence > 12:\n",
    "                    print(\"The value for labelsequence parameter is out of range. It must be be between 1 and 12\")\n",
    "                    raise IndexError\n",
    "                else:\n",
    "\n",
    "                    # Load the data\n",
    "                    fileName = list_file_names[i]\n",
    "\n",
    "                    # Change to a folder where original CSV files are stored\n",
    "                    os.chdir(path_2_csv_files)\n",
    "\n",
    "                    print(\"Processing file : \" + list_file_names[i])\n",
    "\n",
    "                    # Read each file by using pandas\n",
    "                    df = pd.read_csv(fileName, delimiter=',')\n",
    "                    \n",
    "                    \n",
    "                    df['UnixTimeStamp'] = df.UnixTimeStamp.apply(lambda x: \"9999999\" if \"BEGIN\" in x else x)\n",
    "                    df['UnixTimeStamp'] = df.UnixTimeStamp.apply(lambda x: \"9999999\" if \"END\" in x else x)\n",
    "\n",
    "                    # Turn the UnixTimeStamp column into a list (we need the marker later on)\n",
    "                    markers = df['UnixTimeStamp'].tolist()\n",
    "\n",
    "                    # Convert string value to integer number\n",
    "                    markers = list( map(int, markers) )\n",
    "                    \n",
    "                    #   Find all experimental markers and print them out.\n",
    "                    indicesOfMarkers = []  # Empty list to contain indices of markers\n",
    "                    for i, c in enumerate(markers):\n",
    "                        if \"9999999\" in str(c) : \n",
    "                            indicesOfMarkers.append(i) \n",
    "                    try:\n",
    "                        number_markers = len(indicesOfMarkers)\n",
    "                        if number_markers != 48:   # check if the number of markers = 48\n",
    "                            raise ValueError(\"The {} file has incorrect number of markers : {} ! It MUST be 48\".format(fileName,number_markers))\n",
    "                    except ValueError as err_unmatch_markers:\n",
    "                        print(err_unmatch_markers)\n",
    "                        raise\n",
    "\n",
    "\n",
    "                    # Create a list of labels for baseline data. We used only averted eye condition in UNITY.\n",
    "                    # It actually does not matter for different eye condition because participant only sees a white screen during the baseline condition)\n",
    "\n",
    "                    # Order = 1 (Averted) Odd subject no. For example, 1, 3, 5, etc.\n",
    "                    oddOrder1 = [\"averted_pre_right_point\", \"averted_pre_left_point\", \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                                    \"averted_post_right_point\", \"averted_post_left_point\"]\n",
    "\n",
    "                    # Order = 1 (Averted) Even subject no. For example, 2, 4, 6, etc.\n",
    "                    evenOrder1 = [\"averted_pre_left_point\", \"averted_pre_right_point\", \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                                    \"averted_post_left_point\", \"averted_post_right_point\"]\n",
    "\n",
    "\n",
    "                    # Put all labels into a list for baseline data\n",
    "                    listOfOrders = []\n",
    "                    listOfOrders.append(oddOrder1)\n",
    "                    listOfOrders.append(evenOrder1)\n",
    "\n",
    "                    # Number that is used to take the label (oddOrder1 atau evenOrder1)\n",
    "                    i_label_taker = 0\n",
    "\n",
    "                    if i % 2 == 0:\n",
    "\n",
    "                        # Even number\n",
    "                        i_label_taker = 0\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        # Odd number\n",
    "                        i_label_taker = 1\n",
    "                    \n",
    "                    chosenOrder = listOfOrders[i_label_taker]\n",
    "\n",
    "                    # Get the first 12 markers' indices and extract the data\n",
    "                    indicesofBaselineMarkers = indicesOfMarkers[:13]\n",
    "\n",
    "                    # Chunk the data based on opening and closing markers \n",
    "                    chunkedData = []\n",
    "                    for i in range(0, 12, 2):\n",
    "\n",
    "                        chunkedData.append(df.iloc[indicesofBaselineMarkers[i] : indicesofBaselineMarkers[i+1], :])\n",
    "                \n",
    "                    # Match pattern EyeTracker-Sx (x = any number)\n",
    "                    regex = r\"\\D{10}-S\\d+\"\n",
    "\n",
    "                    # Create filename that will be used for each condition. There are 6 conditions. See oddOrder1 or evenOrder1\n",
    "                    extracted_file_name_4_baseline = []\n",
    "                    for i in chosenOrder:\n",
    "                        extracted_file_name = re.search(regex,fileName)\n",
    "                        extracted_file_name_4_baseline.append(fileName[extracted_file_name.start() : extracted_file_name.end()] + \"-\" + i + \"_raw.fif\")\n",
    "\n",
    "\n",
    "                    # Save the chunkedData into a separate csv file\n",
    "                    for i, val in tqdm(enumerate(chunkedData), desc = \"Saving process...\"):\n",
    "                        \n",
    "                        # Convert array into dataframe\n",
    "                        df_chunkedData = pd.DataFrame(val)\n",
    "\n",
    "                        # Save dataframe into csv\n",
    "                        os.chdir(path_2_save_baseline_file)\n",
    "                        df_chunkedData.to_csv(extracted_file_name_4_baseline[i],sep= (\",\"))\n",
    "                        \n",
    "\n",
    "    print(f\"All baseline files have been saved in csv format in this path {path_2_save_baseline_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing extract_baseline_eye_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %% Testing extract_baseline_eye_data function\n",
    "\n",
    "# path_2_csv_files = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/\"\n",
    "# path_2_save_baseline_file = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/raw_baseline_eye_data/\"\n",
    "# labelsequence = 1\n",
    "# bad_files=[]\n",
    "\n",
    "# extract_baseline_eye_data(path_2_csv_files, path_2_save_baseline_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract experiment of eye tracker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Extract experimental data\n",
    "\n",
    "# def extract_experiment_eye_data(path_2_csv_files: str, path_2_save_baseline_file: str, labelsequence: int =1, bad_files: list =[]):\n",
    "\"\"\" \n",
    "Extract baseline data from raw Eye Tracker file (*.csv) that was obtained from hyperscanning2-redesign experiment \\n\n",
    "\n",
    "Arguments :\n",
    "    - path_2_csv_files (str) : path to raw Eye tracker file \\n\n",
    "    - path_2_save_baseline_file (str) : path to save extracted baseline file for each condition \\n\n",
    "    - labelsequence (int) : order of pre-defined label sequence, 1 (averted) is default \\n\n",
    "    - bad_files (list) (optional) : file name of raw EyeTracker file, e.g., EyeTracker-S8.csv, that wants to be skipped to process\n",
    "\n",
    "Return :\n",
    "    Extracted *.csv file for each condition of hand (finger pointing and tracking). \n",
    "    There are 6 files in total for each participant.\n",
    "\"\"\"\n",
    "\n",
    "## Temporary\n",
    "path_2_csv_files = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/\"\n",
    "path_2_save_baseline_file = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/raw_baseline_eye_data/\"\n",
    "labelsequence = 1\n",
    "bad_files=[]\n",
    "\n",
    "### \n",
    "\n",
    "list_file_names = []\n",
    "full_path_2_each_file = []\n",
    "\n",
    "for file in os.listdir(path_2_csv_files):\n",
    "\n",
    "    if file.endswith(\".csv\"):\n",
    "\n",
    "        if (file in bad_files):\n",
    "            # Skip the bad file to be processed\n",
    "            print(f\"Skipped bad file : {file}\")\n",
    "            continue\n",
    "\n",
    "        # Populate all file names only\n",
    "        list_file_names.append(file)\n",
    "        list_file_names.sort()\n",
    "\n",
    "\n",
    "    # Iterate all file names\n",
    "\n",
    "    for i in tqdm(range(len(list_file_names)), desc=\"In progress\"):\n",
    "        \n",
    "\n",
    "        try:\n",
    "            labelsequence = int(labelsequence)\n",
    "\n",
    "        except IOError as err_filename:\n",
    "            print(\"The format of file name is not correct or file doesn't exist \\nThe format must be 'EEG-Sx.csv' , x=subject number \")\n",
    "            raise\n",
    "        except ValueError as err_integer:\n",
    "            print(\"The labelsequence input must be integer : \", err_integer)\n",
    "            raise\n",
    "\n",
    "        else:\n",
    "            if  labelsequence < 1 or labelsequence > 12:\n",
    "                print(\"The value for labelsequence parameter is out of range. It must be be between 1 and 12\")\n",
    "                raise IndexError\n",
    "            else:\n",
    "\n",
    "                # Load the data\n",
    "                fileName = list_file_names[i]\n",
    "\n",
    "                # Change to a folder where original CSV files are stored\n",
    "                os.chdir(path_2_csv_files)\n",
    "\n",
    "                print(\"Processing file : \" + list_file_names[i])\n",
    "\n",
    "                # Read each file by using pandas\n",
    "                df = pd.read_csv(fileName, delimiter=',')\n",
    "                \n",
    "                \n",
    "                df['UnixTimeStamp'] = df.UnixTimeStamp.apply(lambda x: \"9999999\" if \"BEGIN\" in x else x)\n",
    "                df['UnixTimeStamp'] = df.UnixTimeStamp.apply(lambda x: \"9999999\" if \"END\" in x else x)\n",
    "\n",
    "                # Turn the UnixTimeStamp column into a list (we need the marker later on)\n",
    "                markers = df['UnixTimeStamp'].tolist()\n",
    "\n",
    "                # Convert string value to integer number\n",
    "                markers = list( map(int, markers) )\n",
    "                \n",
    "                #   Find all experimental markers and print them out.\n",
    "                indicesOfMarkers = []  # Empty list to contain indices of markers\n",
    "                for i, c in enumerate(markers):\n",
    "                    if \"9999999\" in str(c) : \n",
    "                        indicesOfMarkers.append(i) \n",
    "                try:\n",
    "                    number_markers = len(indicesOfMarkers)\n",
    "                    if number_markers != 48:   # check if the number of markers = 48\n",
    "                        raise ValueError(\"The {} file has incorrect number of markers : {} ! It MUST be 48\".format(fileName,number_markers))\n",
    "                except ValueError as err_unmatch_markers:\n",
    "                    print(err_unmatch_markers)\n",
    "                    raise\n",
    "\n",
    "\n",
    "                # Create a list of labels for baseline data. We used only averted eye condition in UNITY.\n",
    "                # It actually does not matter for different eye condition because participant only sees a white screen during the baseline condition)\n",
    "\n",
    "                # Order = 1 (Averted) Odd subject no. For example, 1, 3, 5, etc.\n",
    "                oddOrder1 = [\"averted_pre_right_point\", \"averted_pre_left_point\", \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                                \"averted_post_right_point\", \"averted_post_left_point\"]\n",
    "\n",
    "                # Order = 1 (Averted) Even subject no. For example, 2, 4, 6, etc.\n",
    "                evenOrder1 = [\"averted_pre_left_point\", \"averted_pre_right_point\", \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                                \"averted_post_left_point\", \"averted_post_right_point\"]\n",
    "\n",
    "\n",
    "                # Put all labels into a list for baseline data\n",
    "                listOfOrders = []\n",
    "                listOfOrders.append(oddOrder1)\n",
    "                listOfOrders.append(evenOrder1)\n",
    "\n",
    "                # Number that is used to take the label (oddOrder1 atau evenOrder1)\n",
    "                i_label_taker = 0\n",
    "\n",
    "                if i % 2 == 0:\n",
    "\n",
    "                    # Even number\n",
    "                    i_label_taker = 0\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # Odd number\n",
    "                    i_label_taker = 1\n",
    "                \n",
    "                chosenOrder = listOfOrders[i_label_taker]\n",
    "\n",
    "                # Get the first 12 markers' indices and extract the data\n",
    "                indicesofBaselineMarkers = indicesOfMarkers[:13]\n",
    "\n",
    "                # Chunk the data based on opening and closing markers \n",
    "                chunkedData = []\n",
    "                for i in range(0, 12, 2):\n",
    "\n",
    "                    chunkedData.append(df.iloc[indicesofBaselineMarkers[i] : indicesofBaselineMarkers[i+1], :])\n",
    "            \n",
    "                # Match pattern EyeTracker-Sx (x = any number)\n",
    "                regex = r\"\\D{10}-S\\d+\"\n",
    "\n",
    "                # Create filename that will be used for each condition. There are 6 conditions. See oddOrder1 or evenOrder1\n",
    "                extracted_file_name_4_baseline = []\n",
    "                for i in chosenOrder:\n",
    "                    extracted_file_name = re.search(regex,fileName)\n",
    "                    extracted_file_name_4_baseline.append(fileName[extracted_file_name.start() : extracted_file_name.end()] + \"-\" + i + \"_raw.fif\")\n",
    "\n",
    "\n",
    "                # Save the chunkedData into a separate csv file\n",
    "                for i, val in tqdm(enumerate(chunkedData), desc = \"Saving process...\"):\n",
    "                    \n",
    "                    # Convert array into dataframe\n",
    "                    df_chunkedData = pd.DataFrame(val)\n",
    "\n",
    "                    # Save dataframe into csv\n",
    "                    os.chdir(path_2_save_baseline_file)\n",
    "                    df_chunkedData.to_csv(extracted_file_name_4_baseline[i],sep= (\",\"))\n",
    "                    \n",
    "\n",
    "print(f\"All baseline files have been saved in csv format in this path {path_2_save_baseline_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47fc37aba7a737a16a20c27199a7c13238fa88e6b66a32f6f49d540dad6db454"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
