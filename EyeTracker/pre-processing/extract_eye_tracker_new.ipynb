{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import packages\n",
    "import chunk\n",
    "import mne\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "import numbers\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract_baseline_eye_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Extract baseline data\n",
    "\n",
    "\n",
    "def extract_baseline_eye_data(path_2_csv_files: str,\n",
    "                              path_2_save_baseline_file: str,\n",
    "                              bad_files: list = [],\n",
    "                              labelsequence: int = 1):\n",
    "    \"\"\" \n",
    "    Extract baseline data from raw Eye Tracker file (*.csv) that was obtained from hyperscanning2-redesign experiment \\n\n",
    "\n",
    "    Arguments :\n",
    "        - path_2_csv_files (str) : path to raw Eye tracker file \\n\n",
    "        - path_2_save_baseline_file (str) : path to save extracted baseline file for each condition \\n\n",
    "        - bad_files (list) (optional) : file name of raw EyeTracker file, e.g., EyeTracker-S8.csv, that wants to be skipped to process\n",
    "        - labelsequence (int) : order of pre-defined label sequence, 1 (averted) is default \\n\n",
    "\n",
    "    Return :\n",
    "        Extracted *.csv file for each condition of hand (finger pointing and tracking). \n",
    "        There are 6 files in total for each participant.\n",
    "\n",
    "        REMEMBER : All resulted files will be in \"AVERTED\" condition since the baseline condition is in AVERTED condition.\n",
    "    \"\"\"\n",
    "\n",
    "    list_file_names = []\n",
    "    full_path_2_each_file = []\n",
    "\n",
    "    for file in os.listdir(path_2_csv_files):\n",
    "\n",
    "        if file.endswith(\".csv\"):\n",
    "\n",
    "            if (file in bad_files):\n",
    "                # Skip the bad file to be processed\n",
    "                print(f\"Skipped bad file : {file}\")\n",
    "                continue\n",
    "\n",
    "            # Populate all file names only\n",
    "            list_file_names.append(file)\n",
    "            list_file_names.sort()\n",
    "\n",
    "        # Iterate all file names\n",
    "\n",
    "        for i in tqdm(range(len(list_file_names)), desc=\"In progress\"):\n",
    "\n",
    "            try:\n",
    "                labelsequence = int(labelsequence)\n",
    "\n",
    "            except IOError as err_filename:\n",
    "                print(\n",
    "                    \"The format of file name is not correct or file doesn't exist \\nThe format must be 'EyeTracker-Sx.csv' , x=subject number \"\n",
    "                )\n",
    "                raise\n",
    "            except ValueError as err_integer:\n",
    "                print(\"The labelsequence input must be integer : \",\n",
    "                      err_integer)\n",
    "                raise\n",
    "\n",
    "            else:\n",
    "                if labelsequence < 1 or labelsequence > 12:\n",
    "                    print(\n",
    "                        \"The value for labelsequence parameter is out of range. It must be be between 1 and 12\"\n",
    "                    )\n",
    "                    raise IndexError\n",
    "                else:\n",
    "\n",
    "                    # Load the data\n",
    "                    fileName = list_file_names[i]\n",
    "\n",
    "                    # Change to a folder where original CSV files are stored\n",
    "                    os.chdir(path_2_csv_files)\n",
    "\n",
    "                    print(\"Processing file : \" + list_file_names[i])\n",
    "\n",
    "                    # Read each file by using pandas\n",
    "                    df = pd.read_csv(fileName, delimiter=',')\n",
    "\n",
    "                    df['UnixTimeStamp'] = df.UnixTimeStamp.apply(\n",
    "                        lambda x: \"9999999\" if \"BEGIN\" in x else x)\n",
    "                    df['UnixTimeStamp'] = df.UnixTimeStamp.apply(\n",
    "                        lambda x: \"9999999\" if \"END\" in x else x)\n",
    "\n",
    "                    # Turn the UnixTimeStamp column into a list (we need the marker later on)\n",
    "                    markers = df['UnixTimeStamp'].tolist()\n",
    "\n",
    "                    # Convert string value to integer number\n",
    "                    markers = list(map(int, markers))\n",
    "\n",
    "                    #   Find all experimental markers and print them out.\n",
    "                    indicesOfMarkers = [\n",
    "                    ]  # Empty list to contain indices of markers\n",
    "                    for i, c in enumerate(markers):\n",
    "                        if \"9999999\" in str(c):\n",
    "                            indicesOfMarkers.append(i)\n",
    "                    try:\n",
    "                        number_markers = len(indicesOfMarkers)\n",
    "                        if number_markers != 48:  # check if the number of markers = 48\n",
    "                            raise ValueError(\n",
    "                                \"The {} file has incorrect number of markers : {} ! It MUST be 48\"\n",
    "                                .format(fileName, number_markers))\n",
    "                    except ValueError as err_unmatch_markers:\n",
    "                        print(err_unmatch_markers)\n",
    "                        raise\n",
    "\n",
    "                    # Create a list of labels for baseline data. We used only averted eye condition in UNITY.\n",
    "                    # It actually does not matter for different eye condition because participant only sees a white screen during the baseline condition)\n",
    "\n",
    "                    # Order = 1 (Averted) Odd subject no. For example, 1, 3, 5, etc.\n",
    "                    oddOrder1 = [\n",
    "                        \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                        \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                        \"averted_post_right_point\", \"averted_post_left_point\"\n",
    "                    ]\n",
    "\n",
    "                    # Order = 1 (Averted) Even subject no. For example, 2, 4, 6, etc.\n",
    "                    evenOrder1 = [\n",
    "                        \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                        \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                        \"averted_post_left_point\", \"averted_post_right_point\"\n",
    "                    ]\n",
    "\n",
    "                    # Put all labels into a list for baseline data\n",
    "                    listOfOrders = []\n",
    "                    listOfOrders.append(oddOrder1)\n",
    "                    listOfOrders.append(evenOrder1)\n",
    "\n",
    "                    # Number that is used to take the label (oddOrder1 atau evenOrder1)\n",
    "                    i_label_taker = 0\n",
    "\n",
    "                    if i % 2 == 0:\n",
    "\n",
    "                        # Even number\n",
    "                        i_label_taker = 0\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        # Odd number\n",
    "                        i_label_taker = 1\n",
    "\n",
    "                    chosenOrder = listOfOrders[i_label_taker]\n",
    "\n",
    "                    # Get the first 12 markers' indices and extract the data\n",
    "                    indicesofBaselineMarkers = indicesOfMarkers[:12]\n",
    "\n",
    "                    # Chunk the data based on opening and closing markers\n",
    "                    chunkedData = []\n",
    "                    for i in range(0, len(indicesofBaselineMarkers), 2):\n",
    "\n",
    "                        chunkedData.append(\n",
    "                            df.iloc[indicesofBaselineMarkers[i]:\n",
    "                                    indicesofBaselineMarkers[i + 1], :])\n",
    "                   \n",
    "                    # Match pattern EyeTracker-Sx (x = any number)\n",
    "                    regex = r\"\\D{10}-S\\d+\"\n",
    "\n",
    "                    # Create filename that will be used for each condition. There are 6 conditions. See oddOrder1 or evenOrder1\n",
    "                    extracted_file_name_4_baseline = []\n",
    "                    for i in chosenOrder:\n",
    "                        extracted_file_name = re.search(regex, fileName)\n",
    "                        extracted_file_name_4_baseline.append(\n",
    "                            fileName[extracted_file_name.start(\n",
    "                            ):extracted_file_name.end()] + \"-\" + i +\n",
    "                            \"_raw.csv\")\n",
    "\n",
    "                    # Save the chunkedData into a separate csv file\n",
    "                    for i, val in tqdm(enumerate(chunkedData),\n",
    "                                       desc=\"Saving process...\"):\n",
    "\n",
    "                        # Convert array into dataframe\n",
    "                        df_chunkedData = pd.DataFrame(val)\n",
    "\n",
    "                        # Save dataframe into csv\n",
    "                        os.chdir(path_2_save_baseline_file)\n",
    "                        df_chunkedData.to_csv(\n",
    "                            extracted_file_name_4_baseline[i], sep=(\",\"))\n",
    "\n",
    "    print(\n",
    "        f\"All baseline files of eye data have been saved in csv format in this path {path_2_save_baseline_file}\"\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running extract_baseline_eye_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsequence = 1\n",
    "path_2_csv_files = \"/hpc/igum002/codes/Hyperscanning2-redesign/data/EyeTracker\"\n",
    "path_2_save_baseline_eyetracker_file = \"/hpc/igum002/codes/Hyperscanning2-redesign/data/EyeTracker/raw_baseline_eye_data\"\n",
    "\n",
    "# Bad files temporary\n",
    "bad_files = [\"EyeTracker-S16.csv\"]\n",
    "\n",
    "extract_baseline_eye_data(path_2_csv_files, path_2_save_baseline_eyetracker_file, bad_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract_experiment_eye_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import packages\n",
    "import chunk\n",
    "import mne\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "import numbers\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "def extract_experiment_eye_data(path_2_csv_files: str,\n",
    "                                path_2_save_experimental_file: str,\n",
    "                                labelsequence_experiment: list,\n",
    "                                bad_files: list = []):\n",
    "    \"\"\"\n",
    "    Extract experimental data from raw Eye Tracker file (*.csv) that was obtained from hyperscanning2-redesign experiment \\n\n",
    "    Arguments :\n",
    "        - path_2_csv_files (str) : path to raw Eye tracker file \\n\n",
    "        - path_2_save_experimental_file (str) : path to save extracted experimental file for each condition \\n\n",
    "        - labelsequence_experiment (list) : order of pre-defined label sequence \\n\n",
    "        - bad_files (list) (optional) : file name of raw EyeTracker file, e.g., EyeTracker-S8.csv, that wants to be skipped to process\n",
    "    Return :\n",
    "        Extracted *.csv file for each condition of hand (finger pointing and tracking).\n",
    "        There are 6 files in total for each participant.\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    list_file_names = []\n",
    "    full_path_2_each_file = []\n",
    "\n",
    "    for file in os.listdir(path_2_csv_files):\n",
    "\n",
    "        if file.endswith(\".csv\"):\n",
    "\n",
    "            if (file in bad_files):\n",
    "                # Skip the bad file to be processed\n",
    "                print(f\"Skipped bad file : {file}\")\n",
    "                continue\n",
    "\n",
    "            # Populate all file names only\n",
    "            list_file_names.append(file)\n",
    "            list_file_names.sort()\n",
    "\n",
    "    # Iterate all file names\n",
    "\n",
    "    for i in tqdm(range(len(list_file_names)), desc=\"In progress\"):\n",
    "\n",
    "        try:\n",
    "            labelsequence = int(labelsequence_experiment[i])\n",
    "\n",
    "        except IOError as err_filename:\n",
    "            print(\n",
    "                \"The format of file name is not correct or file doesn't exist \\nThe format must be 'EEG-Sx.csv' , x=subject number \"\n",
    "            )\n",
    "            raise\n",
    "        except ValueError as err_integer:\n",
    "            print(\"The labelsequence input must be integer : \",\n",
    "                    err_integer)\n",
    "            raise\n",
    "\n",
    "        else:\n",
    "            if labelsequence < 1 or labelsequence > 12:\n",
    "                print(\n",
    "                    \"The value for labelsequence parameter is out of range. It must be be between 1 and 12\"\n",
    "                )\n",
    "                raise IndexError\n",
    "            else:\n",
    "\n",
    "                # Load the data\n",
    "                fileName = list_file_names[i]\n",
    "\n",
    "                # Change to a folder where original CSV files are stored\n",
    "                os.chdir(path_2_csv_files)\n",
    "\n",
    "                print(\"Processing file : \" + list_file_names[i])\n",
    "\n",
    "                # Read each file by using pandas\n",
    "                df = pd.read_csv(fileName, delimiter=',')\n",
    "\n",
    "                df['UnixTimeStamp'] = df.UnixTimeStamp.apply(\n",
    "                    lambda x: \"9999999\" if \"BEGIN\" in x else x)\n",
    "                df['UnixTimeStamp'] = df.UnixTimeStamp.apply(\n",
    "                    lambda x: \"9999999\" if \"END\" in x else x)\n",
    "\n",
    "                # Turn the UnixTimeStamp column into a list (we need the marker later on)\n",
    "                markers = df['UnixTimeStamp'].tolist()\n",
    "\n",
    "                # Convert string value to integer number\n",
    "                markers = list(map(int, markers))\n",
    "\n",
    "                #   Find all experimental markers and print them out.\n",
    "                indicesOfMarkers = [\n",
    "                ]  # Empty list to contain indices of markers\n",
    "                for i, c in enumerate(markers):\n",
    "                    if \"9999999\" in str(c):\n",
    "                        indicesOfMarkers.append(i)\n",
    "                try:\n",
    "                    number_markers = len(indicesOfMarkers)\n",
    "                    if number_markers != 48:  # check if the number of markers = 48\n",
    "                        raise ValueError(\n",
    "                            \"The {} file has incorrect number of markers : {} ! It MUST be 48\"\n",
    "                            .format(fileName, number_markers))\n",
    "                except ValueError as err_unmatch_markers:\n",
    "                    print(err_unmatch_markers)\n",
    "                    raise\n",
    "\n",
    "                # Create a list of labels for experimental data.\n",
    "\n",
    "                # Order = 1 (Averted/Direct/Natural)\n",
    "                oddOrder1 = [\n",
    "                    \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                    \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                    \"averted_post_right_point\", \"averted_post_left_point\",\n",
    "                    \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                    \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                    \"direct_post_right_point\", \"direct_post_left_point\",\n",
    "                    \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                    \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                    \"natural_post_right_point\", \"natural_post_left_point\"\n",
    "                ]\n",
    "\n",
    "                evenOrder1 = [\n",
    "                    \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                    \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                    \"averted_post_left_point\", \"averted_post_right_point\",\n",
    "                    \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                    \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                    \"direct_post_left_point\", \"direct_post_right_point\",\n",
    "                    \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                    \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                    \"natural_post_left_point\", \"natural_post_right_point\"\n",
    "                ]\n",
    "\n",
    "                # Order = 2 (Averted/Natural/Direct)\n",
    "                oddOrder2 = [\n",
    "                    \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                    \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                    \"averted_post_right_point\", \"averted_post_left_point\",\n",
    "                    \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                    \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                    \"natural_post_right_point\", \"natural_post_left_point\",\n",
    "                    \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                    \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                    \"direct_post_right_point\", \"direct_post_left_point\"\n",
    "                ]\n",
    "\n",
    "                evenOrder2 = [\n",
    "                    \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                    \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                    \"averted_post_left_point\", \"averted_post_right_point\",\n",
    "                    \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                    \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                    \"natural_post_left_point\", \"natural_post_right_point\",\n",
    "                    \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                    \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                    \"direct_post_left_point\", \"direct_post_right_point\"\n",
    "                ]\n",
    "\n",
    "                # Order = 3 (Direct / Natural / Averted)\n",
    "                oddOrder3 = [\n",
    "                    \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                    \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                    \"direct_post_right_point\", \"direct_post_left_point\",\n",
    "                    \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                    \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                    \"natural_post_right_point\", \"natural_post_left_point\",\n",
    "                    \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                    \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                    \"averted_post_right_point\", \"averted_post_left_point\"\n",
    "                ]\n",
    "\n",
    "                evenOrder3 = [\n",
    "                    \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                    \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                    \"direct_post_left_point\", \"direct_post_right_point\",\n",
    "                    \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                    \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                    \"natural_post_left_point\", \"natural_post_right_point\",\n",
    "                    \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                    \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                    \"averted_post_left_point\", \"averted_post_right_point\"\n",
    "                ]\n",
    "\n",
    "                # Order = 4 (Direct/Averted/Natural)\n",
    "                oddOrder4 = [\n",
    "                    \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                    \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                    \"direct_post_right_point\", \"direct_post_left_point\",\n",
    "                    \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                    \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                    \"averted_post_right_point\", \"averted_post_left_point\",\n",
    "                    \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                    \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                    \"natural_post_right_point\", \"natural_post_left_point\"\n",
    "                ]\n",
    "\n",
    "                evenOrder4 = [\n",
    "                    \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                    \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                    \"direct_post_left_point\", \"direct_post_right_point\",\n",
    "                    \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                    \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                    \"averted_post_left_point\", \"averted_post_right_point\",\n",
    "                    \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                    \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                    \"natural_post_left_point\", \"natural_post_right_point\"\n",
    "                ]\n",
    "\n",
    "                # Order = 5 (Natural/Direct/Averted)\n",
    "                oddOrder5 = [\n",
    "                    \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                    \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                    \"natural_post_right_point\", \"natural_post_left_point\",\n",
    "                    \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                    \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                    \"direct_post_right_point\", \"direct_post_left_point\",\n",
    "                    \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                    \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                    \"averted_post_right_point\", \"averted_post_left_point\"\n",
    "                ]\n",
    "\n",
    "                evenOrder5 = [\n",
    "                    \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                    \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                    \"natural_post_left_point\", \"natural_post_right_point\",\n",
    "                    \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                    \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                    \"direct_post_left_point\", \"direct_post_right_point\",\n",
    "                    \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                    \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                    \"averted_post_left_point\", \"averted_post_right_point\"\n",
    "                ]\n",
    "\n",
    "                # Order = 6 (Natural/Averted/Direct)\n",
    "                oddOrder6 = [\n",
    "                    \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                    \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                    \"natural_post_right_point\", \"natural_post_left_point\",\n",
    "                    \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                    \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                    \"averted_post_right_point\", \"averted_post_left_point\",\n",
    "                    \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                    \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                    \"direct_post_right_point\", \"direct_post_left_point\"\n",
    "                ]\n",
    "\n",
    "                evenOrder6 = [\n",
    "                    \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                    \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                    \"natural_post_left_point\", \"natural_post_right_point\",\n",
    "                    \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                    \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                    \"averted_post_left_point\", \"averted_post_right_point\",\n",
    "                    \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                    \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                    \"direct_post_left_point\", \"direct_post_right_point\"\n",
    "                ]\n",
    "\n",
    "                # Populate all orders\n",
    "                listOfOrders = []\n",
    "                for i in tqdm(range(6)):\n",
    "                    listOfOrders.append(eval('oddOrder' + str(i + 1)))\n",
    "                    listOfOrders.append(eval('evenOrder' + str(i + 1)))\n",
    "\n",
    "                labelsequence = labelsequence - 1\n",
    "                chosenOrder = listOfOrders[labelsequence - 1]\n",
    "\n",
    "                # Get the experimental markers' indices and extract the data\n",
    "                indicesofExperimentalMarkers = indicesOfMarkers[12:]\n",
    "\n",
    "                # Chunk the data based on opening and closing markers\n",
    "                chunkedData = []\n",
    "                for i in range(0, len(indicesofExperimentalMarkers),2):\n",
    "\n",
    "                    chunkedData.append(\n",
    "                        df.iloc[indicesofExperimentalMarkers[i]:\n",
    "                                indicesofExperimentalMarkers[i + 1], :])\n",
    "\n",
    "\n",
    "                # Match pattern EyeTracker-Sx (x = any number)\n",
    "                regex = r\"\\D{10}-S\\d+\"\n",
    "\n",
    "                # Create filename that will be used for each condition. There are 6 conditions. See oddOrder1 or evenOrder1\n",
    "                extracted_file_name_4_experimental = []\n",
    "                for i in chosenOrder:\n",
    "                    extracted_file_name = re.search(regex, fileName)\n",
    "                    extracted_file_name_4_experimental.append(\n",
    "                        fileName[extracted_file_name.start(\n",
    "                        ):extracted_file_name.end()] + \"-\" + i +\n",
    "                        \"_raw.csv\")\n",
    "\n",
    "                # Save the chunkedData into a separate csv file\n",
    "                for i, val in tqdm(enumerate(chunkedData),\n",
    "                                    desc=\"Saving process...\"):\n",
    "\n",
    "                    # Convert array into dataframe\n",
    "                    df_chunkedData = pd.DataFrame(val)\n",
    "\n",
    "                    # Save dataframe into csv\n",
    "                    os.chdir(path_2_save_experimental_file)\n",
    "                    df_chunkedData.to_csv(\n",
    "                        extracted_file_name_4_experimental[i], sep=(\",\"))\n",
    "\n",
    "    print(\n",
    "        f\"All experimental files of eye data have been saved in csv format in this path {path_2_save_experimental_file}\"\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function to extract baseline and experimental eye data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running extract_experiment_eye_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsequence = [1,2,1,2,1,2,3,4,3,4,3,4,5,6,5,6]\n",
    "path_2_csv_files = \"/hpc/igum002/codes/Hyperscanning2-redesign/data/EyeTracker\"\n",
    "path_2_save_experimental_eyetracker_file = \"/hpc/igum002/codes/Hyperscanning2-redesign/data/EyeTracker/raw_experimental_eye_data\"\n",
    "\n",
    "# Bad files temporary\n",
    "bad_files = [\"EyeTracker-S16.csv\"]\n",
    "\n",
    "\n",
    "extract_experiment_eye_data(path_2_csv_files, path_2_save_experimental_eyetracker_file, labelsequence, bad_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47fc37aba7a737a16a20c27199a7c13238fa88e6b66a32f6f49d540dad6db454"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
