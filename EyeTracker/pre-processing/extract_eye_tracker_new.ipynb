{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import packages\n",
    "import chunk\n",
    "import mne\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "import numbers\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract baseline of eye tracker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Extract baseline data\n",
    "\n",
    "def extract_baseline_eye_data(path_2_csv_files: str, path_2_save_baseline_file: str, labelsequence: int =1, bad_files: list =[]):\n",
    "    \"\"\" \n",
    "    Extract baseline data from raw Eye Tracker file (*.csv) that was obtained from hyperscanning2-redesign experiment \\n\n",
    "\n",
    "    Arguments :\n",
    "        - path_2_csv_files (str) : path to raw Eye tracker file \\n\n",
    "        - path_2_save_baseline_file (str) : path to save extracted baseline file for each condition \\n\n",
    "        - labelsequence (int) : order of pre-defined label sequence, 1 (averted) is default \\n\n",
    "        - bad_files (list) (optional) : file name of raw EyeTracker file, e.g., EyeTracker-S8.csv, that wants to be skipped to process\n",
    "\n",
    "    Return :\n",
    "        Extracted *.csv file for each condition of hand (finger pointing and tracking). \n",
    "        There are 6 files in total for each participant.\n",
    "    \"\"\"\n",
    "\n",
    "    ## Temporary\n",
    "    # path_2_csv_files = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/\"\n",
    "    # path_2_save_baseline_file = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/raw_baseline_eye_data/\"\n",
    "    # labelsequence = 1\n",
    "    # bad_files=[]\n",
    "\n",
    "    ### \n",
    "\n",
    "    list_file_names = []\n",
    "    full_path_2_each_file = []\n",
    "   \n",
    "    for file in os.listdir(path_2_csv_files):\n",
    "\n",
    "        if file.endswith(\".csv\"):\n",
    "\n",
    "            if (file in bad_files):\n",
    "                # Skip the bad file to be processed\n",
    "                print(f\"Skipped bad file : {file}\")\n",
    "                continue\n",
    "\n",
    "            # Populate all file names only\n",
    "            list_file_names.append(file)\n",
    "            list_file_names.sort()\n",
    "\n",
    "\n",
    "        # Iterate all file names\n",
    "\n",
    "        for i in tqdm(range(len(list_file_names)), desc=\"In progress\"):\n",
    "            \n",
    "\n",
    "            try:\n",
    "                labelsequence = int(labelsequence)\n",
    "\n",
    "            except IOError as err_filename:\n",
    "                print(\"The format of file name is not correct or file doesn't exist \\nThe format must be 'EyeTracker-Sx.csv' , x=subject number \")\n",
    "                raise\n",
    "            except ValueError as err_integer:\n",
    "                print(\"The labelsequence input must be integer : \", err_integer)\n",
    "                raise\n",
    "\n",
    "            else:\n",
    "                if  labelsequence < 1 or labelsequence > 12:\n",
    "                    print(\"The value for labelsequence parameter is out of range. It must be be between 1 and 12\")\n",
    "                    raise IndexError\n",
    "                else:\n",
    "\n",
    "                    # Load the data\n",
    "                    fileName = list_file_names[i]\n",
    "\n",
    "                    # Change to a folder where original CSV files are stored\n",
    "                    os.chdir(path_2_csv_files)\n",
    "\n",
    "                    print(\"Processing file : \" + list_file_names[i])\n",
    "\n",
    "                    # Read each file by using pandas\n",
    "                    df = pd.read_csv(fileName, delimiter=',')\n",
    "                    \n",
    "                    \n",
    "                    df['UnixTimeStamp'] = df.UnixTimeStamp.apply(lambda x: \"9999999\" if \"BEGIN\" in x else x)\n",
    "                    df['UnixTimeStamp'] = df.UnixTimeStamp.apply(lambda x: \"9999999\" if \"END\" in x else x)\n",
    "\n",
    "                    # Turn the UnixTimeStamp column into a list (we need the marker later on)\n",
    "                    markers = df['UnixTimeStamp'].tolist()\n",
    "\n",
    "                    # Convert string value to integer number\n",
    "                    markers = list( map(int, markers) )\n",
    "                    \n",
    "                    #   Find all experimental markers and print them out.\n",
    "                    indicesOfMarkers = []  # Empty list to contain indices of markers\n",
    "                    for i, c in enumerate(markers):\n",
    "                        if \"9999999\" in str(c) : \n",
    "                            indicesOfMarkers.append(i) \n",
    "                    try:\n",
    "                        number_markers = len(indicesOfMarkers)\n",
    "                        if number_markers != 48:   # check if the number of markers = 48\n",
    "                            raise ValueError(\"The {} file has incorrect number of markers : {} ! It MUST be 48\".format(fileName,number_markers))\n",
    "                    except ValueError as err_unmatch_markers:\n",
    "                        print(err_unmatch_markers)\n",
    "                        raise\n",
    "\n",
    "\n",
    "                    # Create a list of labels for baseline data. We used only averted eye condition in UNITY.\n",
    "                    # It actually does not matter for different eye condition because participant only sees a white screen during the baseline condition)\n",
    "\n",
    "                    # Order = 1 (Averted) Odd subject no. For example, 1, 3, 5, etc.\n",
    "                    oddOrder1 = [\"averted_pre_right_point\", \"averted_pre_left_point\", \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                                    \"averted_post_right_point\", \"averted_post_left_point\"]\n",
    "\n",
    "                    # Order = 1 (Averted) Even subject no. For example, 2, 4, 6, etc.\n",
    "                    evenOrder1 = [\"averted_pre_left_point\", \"averted_pre_right_point\", \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                                    \"averted_post_left_point\", \"averted_post_right_point\"]\n",
    "\n",
    "\n",
    "                    # Put all labels into a list for baseline data\n",
    "                    listOfOrders = []\n",
    "                    listOfOrders.append(oddOrder1)\n",
    "                    listOfOrders.append(evenOrder1)\n",
    "\n",
    "                    # Number that is used to take the label (oddOrder1 atau evenOrder1)\n",
    "                    i_label_taker = 0\n",
    "\n",
    "                    if i % 2 == 0:\n",
    "\n",
    "                        # Even number\n",
    "                        i_label_taker = 0\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        # Odd number\n",
    "                        i_label_taker = 1\n",
    "                    \n",
    "                    chosenOrder = listOfOrders[i_label_taker]\n",
    "\n",
    "                    # Get the first 12 markers' indices and extract the data\n",
    "                    indicesofBaselineMarkers = indicesOfMarkers[:13]\n",
    "\n",
    "                    # Chunk the data based on opening and closing markers \n",
    "                    chunkedData = []\n",
    "                    for i in range(0, 12, 2):\n",
    "\n",
    "                        chunkedData.append(df.iloc[indicesofBaselineMarkers[i] : indicesofBaselineMarkers[i+1], :])\n",
    "                \n",
    "                    # Match pattern EyeTracker-Sx (x = any number)\n",
    "                    regex = r\"\\D{10}-S\\d+\"\n",
    "\n",
    "                    # Create filename that will be used for each condition. There are 6 conditions. See oddOrder1 or evenOrder1\n",
    "                    extracted_file_name_4_baseline = []\n",
    "                    for i in chosenOrder:\n",
    "                        extracted_file_name = re.search(regex,fileName)\n",
    "                        extracted_file_name_4_baseline.append(fileName[extracted_file_name.start() : extracted_file_name.end()] + \"-\" + i + \"_raw.csv\")\n",
    "\n",
    "\n",
    "                    # Save the chunkedData into a separate csv file\n",
    "                    for i, val in tqdm(enumerate(chunkedData), desc = \"Saving process...\"):\n",
    "                        \n",
    "                        # Convert array into dataframe\n",
    "                        df_chunkedData = pd.DataFrame(val)\n",
    "\n",
    "                        # Save dataframe into csv\n",
    "                        os.chdir(path_2_save_baseline_file)\n",
    "                        df_chunkedData.to_csv(extracted_file_name_4_baseline[i],sep= (\",\"))\n",
    "                        \n",
    "\n",
    "    print(f\"All baseline files of eye data have been saved in csv format in this path {path_2_save_baseline_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing extract_baseline_eye_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In progress: 0it [00:00, ?it/s]\n",
      "In progress:   0%|                                        | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : EyeTracker-S1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving process...: 6it [00:00, 28.19it/s]\n",
      "In progress: 100%|████████████████████████████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "In progress:   0%|                                        | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : EyeTracker-S1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving process...: 6it [00:00, 28.51it/s]\n",
      "In progress:  50%|████████████████                | 1/2 [00:00<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : EyeTracker-S3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving process...: 6it [00:00, 27.69it/s]\n",
      "In progress: 100%|████████████████████████████████| 2/2 [00:00<00:00,  2.82it/s]\n",
      "In progress:   0%|                                        | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : EyeTracker-S1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving process...: 6it [00:00, 28.21it/s]\n",
      "In progress:  33%|██████████▋                     | 1/3 [00:00<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : EyeTracker-S2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving process...: 6it [00:00, 28.29it/s]\n",
      "In progress:  67%|█████████████████████▎          | 2/3 [00:00<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : EyeTracker-S3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving process...: 6it [00:00, 27.66it/s]\n",
      "In progress: 100%|████████████████████████████████| 3/3 [00:01<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All baseline files have been saved in csv format in this path /hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/raw_baseline_eye_data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %% Testing extract_baseline_eye_data function\n",
    "\n",
    "path_2_csv_files = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/\"\n",
    "path_2_save_baseline_file = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/raw_baseline_eye_data/\"\n",
    "labelsequence = 1\n",
    "bad_files=[]\n",
    "\n",
    "extract_baseline_eye_data(path_2_csv_files, path_2_save_baseline_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract experiment of eye tracker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In progress: 0it [00:00, ?it/s]\n",
      "In progress:   0%|                                        | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : EyeTracker-S1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 29606.85it/s]\n",
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 38716.65it/s]\n",
      "Saving process...: 6it [00:00, 134.80it/s]\n",
      "In progress: 100%|████████████████████████████████| 1/1 [00:00<00:00,  5.28it/s]\n",
      "In progress:   0%|                                        | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : EyeTracker-S1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 30652.65it/s]\n",
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 37900.34it/s]\n",
      "Saving process...: 6it [00:00, 144.44it/s]\n",
      "In progress:  50%|████████████████                | 1/2 [00:00<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : EyeTracker-S3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 30727.50it/s]\n",
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 37957.50it/s]\n",
      "Saving process...: 6it [00:00, 141.76it/s]\n",
      "In progress: 100%|████████████████████████████████| 2/2 [00:00<00:00,  5.25it/s]\n",
      "In progress:   0%|                                        | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : EyeTracker-S1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 30652.65it/s]\n",
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 38538.78it/s]\n",
      "Saving process...: 6it [00:00, 125.25it/s]\n",
      "In progress:  33%|██████████▋                     | 1/3 [00:00<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : EyeTracker-S2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 30727.50it/s]\n",
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 38304.15it/s]\n",
      "Saving process...: 6it [00:00, 144.70it/s]\n",
      "In progress:  67%|█████████████████████▎          | 2/3 [00:00<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : EyeTracker-S3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 30765.07it/s]\n",
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 38072.35it/s]\n",
      "Saving process...: 6it [00:00, 145.42it/s]\n",
      "In progress: 100%|████████████████████████████████| 3/3 [00:00<00:00,  5.19it/s]\n",
      "In progress:   0%|                                        | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : EyeTracker-S1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 30066.70it/s]\n",
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 38187.90it/s]\n",
      "Saving process...: 6it [00:00, 149.58it/s]\n",
      "In progress:  33%|██████████▋                     | 1/3 [00:00<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : EyeTracker-S2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 30430.26it/s]\n",
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 12564.07it/s]\n",
      "Saving process...: 6it [00:00, 142.80it/s]\n",
      "In progress:  67%|█████████████████████▎          | 2/3 [00:00<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : EyeTracker-S3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 30541.05it/s]\n",
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 12958.71it/s]\n",
      "Saving process...: 6it [00:00, 142.81it/s]\n",
      "In progress: 100%|████████████████████████████████| 3/3 [00:00<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All experimental files of eye data have been saved in csv format in this path /hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/experimental_eye_data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% Extract experimental data\n",
    "\n",
    "# def extract_experiment_eye_data(path_2_csv_files: str, path_2_save_baseline_file: str, labelsequence: int =1, bad_files: list =[]):\n",
    "\"\"\" \n",
    "Extract baseline data from raw Eye Tracker file (*.csv) that was obtained from hyperscanning2-redesign experiment \\n\n",
    "\n",
    "Arguments :\n",
    "    - path_2_csv_files (str) : path to raw Eye tracker file \\n\n",
    "    - path_2_save_baseline_file (str) : path to save extracted baseline file for each condition \\n\n",
    "    - labelsequence (int) : order of pre-defined label sequence, 1 (averted) is default \\n\n",
    "    - bad_files (list) (optional) : file name of raw EyeTracker file, e.g., EyeTracker-S8.csv, that wants to be skipped to process\n",
    "\n",
    "Return :\n",
    "    Extracted *.csv file for each condition of hand (finger pointing and tracking). \n",
    "    There are 6 files in total for each participant.\n",
    "\"\"\"\n",
    "\n",
    "## Temporary\n",
    "path_2_csv_files = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/\"\n",
    "path_2_save_baseline_file = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/experimental_eye_data/\"\n",
    "labelsequence = 1\n",
    "bad_files=[]\n",
    "\n",
    "### \n",
    "\n",
    "list_file_names = []\n",
    "full_path_2_each_file = []\n",
    "\n",
    "for file in os.listdir(path_2_csv_files):\n",
    "\n",
    "    if file.endswith(\".csv\"):\n",
    "\n",
    "        if (file in bad_files):\n",
    "            # Skip the bad file to be processed\n",
    "            print(f\"Skipped bad file : {file}\")\n",
    "            continue\n",
    "\n",
    "        # Populate all file names only\n",
    "        list_file_names.append(file)\n",
    "        list_file_names.sort()\n",
    "\n",
    "\n",
    "    # Iterate all file names\n",
    "\n",
    "    for i in tqdm(range(len(list_file_names)), desc=\"In progress\"):\n",
    "        \n",
    "\n",
    "        try:\n",
    "            labelsequence = int(labelsequence)\n",
    "\n",
    "        except IOError as err_filename:\n",
    "            print(\"The format of file name is not correct or file doesn't exist \\nThe format must be 'EEG-Sx.csv' , x=subject number \")\n",
    "            raise\n",
    "        except ValueError as err_integer:\n",
    "            print(\"The labelsequence input must be integer : \", err_integer)\n",
    "            raise\n",
    "\n",
    "        else:\n",
    "            if  labelsequence < 1 or labelsequence > 12:\n",
    "                print(\"The value for labelsequence parameter is out of range. It must be be between 1 and 12\")\n",
    "                raise IndexError\n",
    "            else:\n",
    "\n",
    "                # Load the data\n",
    "                fileName = list_file_names[i]\n",
    "\n",
    "                # Change to a folder where original CSV files are stored\n",
    "                os.chdir(path_2_csv_files)\n",
    "\n",
    "                print(\"Processing file : \" + list_file_names[i])\n",
    "\n",
    "                # Read each file by using pandas\n",
    "                df = pd.read_csv(fileName, delimiter=',')\n",
    "                \n",
    "                \n",
    "                df['UnixTimeStamp'] = df.UnixTimeStamp.apply(lambda x: \"9999999\" if \"BEGIN\" in x else x)\n",
    "                df['UnixTimeStamp'] = df.UnixTimeStamp.apply(lambda x: \"9999999\" if \"END\" in x else x)\n",
    "\n",
    "                # Turn the UnixTimeStamp column into a list (we need the marker later on)\n",
    "                markers = df['UnixTimeStamp'].tolist()\n",
    "\n",
    "                # Convert string value to integer number\n",
    "                markers = list( map(int, markers) )\n",
    "                \n",
    "                #   Find all experimental markers and print them out.\n",
    "                indicesOfMarkers = []  # Empty list to contain indices of markers\n",
    "                for i, c in enumerate(markers):\n",
    "                    if \"9999999\" in str(c) : \n",
    "                        indicesOfMarkers.append(i) \n",
    "                try:\n",
    "                    number_markers = len(indicesOfMarkers)\n",
    "                    if number_markers != 48:   # check if the number of markers = 48\n",
    "                        raise ValueError(\"The {} file has incorrect number of markers : {} ! It MUST be 48\".format(fileName,number_markers))\n",
    "                except ValueError as err_unmatch_markers:\n",
    "                    print(err_unmatch_markers)\n",
    "                    raise\n",
    "\n",
    "\n",
    "                # Create a list of labels for experimental data.\n",
    "\n",
    "                # Order = 1 (Averted/Direct/Natural)\n",
    "                oddOrder1 = [\"averted_pre_right_point\", \"averted_pre_left_point\", \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                            \"averted_post_right_point\", \"averted_post_left_point\", \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                            \"direct_left_tracking\", \"direct_right_tracking\", \"direct_post_right_point\", \"direct_post_left_point\",\n",
    "                            \"natural_pre_right_point\", \"natural_pre_left_point\", \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                            \"natural_post_right_point\", \"natural_post_left_point\"]\n",
    "\n",
    "                evenOrder1 = [\"averted_pre_left_point\", \"averted_pre_right_point\", \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                            \"averted_post_left_point\", \"averted_post_right_point\", \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                            \"direct_right_tracking\", \"direct_left_tracking\", \"direct_post_left_point\", \"direct_post_right_point\",\n",
    "                            \"natural_pre_left_point\", \"natural_pre_right_point\", \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                            \"natural_post_left_point\", \"natural_post_right_point\"]\n",
    "\n",
    "                # Order = 2 (Averted/Natural/Direct)\n",
    "                oddOrder2 = [\"averted_pre_right_point\", \"averted_pre_left_point\", \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                            \"averted_post_right_point\", \"averted_post_left_point\", \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                            \"natural_left_tracking\", \"natural_right_tracking\", \"natural_post_right_point\", \"natural_post_left_point\",\n",
    "                            \"direct_pre_right_point\", \"direct_pre_left_point\", \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                            \"direct_post_right_point\", \"direct_post_left_point\"]\n",
    "\n",
    "                evenOrder2 = [\"averted_pre_left_point\", \"averted_pre_right_point\", \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                            \"averted_post_left_point\", \"averted_post_right_point\", \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                            \"natural_right_tracking\", \"natural_left_tracking\", \"natural_post_left_point\", \"natural_post_right_point\",\n",
    "                            \"direct_pre_left_point\", \"direct_pre_right_point\", \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                            \"direct_post_left_point\", \"direct_post_right_point\"]\n",
    "\n",
    "                # Order = 3 (Direct / Natural / Averted)\n",
    "                oddOrder3 = [\"direct_pre_right_point\", \"direct_pre_left_point\", \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                            \"direct_post_right_point\", \"direct_post_left_point\", \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                            \"natural_left_tracking\", \"natural_right_tracking\", \"natural_post_right_point\", \"natural_post_left_point\",\n",
    "                            \"averted_pre_right_point\", \"averted_pre_left_point\", \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                            \"averted_post_right_point\", \"averted_post_left_point\"]\n",
    "\n",
    "                evenOrder3 = [\"direct_pre_left_point\", \"direct_pre_right_point\", \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                            \"direct_post_left_point\", \"direct_post_right_point\", \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                            \"natural_right_tracking\", \"natural_left_tracking\", \"natural_post_left_point\", \"natural_post_right_point\",\n",
    "                            \"averted_pre_left_point\", \"averted_pre_right_point\", \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                            \"averted_post_left_point\", \"averted_post_right_point\"]\n",
    "\n",
    "                # Order = 4 (Direct/Averted/Natural)\n",
    "                oddOrder4 = [\"direct_pre_right_point\", \"direct_pre_left_point\", \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                            \"direct_post_right_point\", \"direct_post_left_point\", \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                            \"averted_left_tracking\", \"averted_right_tracking\", \"averted_post_right_point\", \"averted_post_left_point\",\n",
    "                            \"natural_pre_right_point\", \"natural_pre_left_point\", \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                            \"natural_post_right_point\", \"natural_post_left_point\"]\n",
    "\n",
    "                evenOrder4 = [\"direct_pre_left_point\", \"direct_pre_right_point\", \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                            \"direct_post_left_point\", \"direct_post_right_point\", \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                            \"averted_right_tracking\", \"averted_left_tracking\", \"averted_post_left_point\", \"averted_post_right_point\",\n",
    "                            \"natural_pre_left_point\", \"natural_pre_right_point\", \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                            \"natural_post_left_point\", \"natural_post_right_point\"]\n",
    "\n",
    "                # Order = 5 (Natural/Direct/Averted)\n",
    "                oddOrder5 = [\"natural_pre_right_point\", \"natural_pre_left_point\", \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                            \"natural_post_right_point\", \"natural_post_left_point\", \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                            \"direct_left_tracking\", \"direct_right_tracking\", \"direct_post_right_point\", \"direct_post_left_point\",\n",
    "                            \"averted_pre_right_point\", \"averted_pre_left_point\", \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                            \"averted_post_right_point\", \"averted_post_left_point\"]\n",
    "\n",
    "                evenOrder5 = [\"natural_pre_left_point\", \"natural_pre_right_point\", \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                            \"natural_post_left_point\", \"natural_post_right_point\", \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                            \"direct_right_tracking\", \"direct_left_tracking\", \"direct_post_left_point\", \"direct_post_right_point\",\n",
    "                            \"averted_pre_left_point\", \"averted_pre_right_point\", \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                            \"averted_post_left_point\", \"averted_post_right_point\"]\n",
    "\n",
    "                # Order = 6 (Natural/Averted/Direct)\n",
    "                oddOrder6 = [\"natural_pre_right_point\", \"natural_pre_left_point\", \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                            \"natural_post_right_point\", \"natural_post_left_point\", \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                            \"averted_left_tracking\", \"averted_right_tracking\", \"averted_post_right_point\", \"averted_post_left_point\",\n",
    "                            \"direct_pre_right_point\", \"direct_pre_left_point\", \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                            \"direct_post_right_point\", \"direct_post_left_point\"]\n",
    "\n",
    "                evenOrder6 = [\"natural_pre_left_point\", \"natural_pre_right_point\", \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                            \"natural_post_left_point\", \"natural_post_right_point\", \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                            \"averted_right_tracking\", \"averted_left_tracking\", \"averted_post_left_point\", \"averted_post_right_point\",\n",
    "                            \"direct_pre_left_point\", \"direct_pre_right_point\", \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                            \"direct_post_left_point\", \"direct_post_right_point\"]\n",
    "\n",
    "\n",
    "                # # Put all labels into a list for baseline data\n",
    "                # listOfOrders = []\n",
    "                # listOfOrders.append(oddOrder1)\n",
    "                # listOfOrders.append(evenOrder1)\n",
    "\n",
    "                # Populate all orders\n",
    "                listOfOrders = []\n",
    "                for i in tqdm(range(6)):\n",
    "                    listOfOrders.append(eval('oddOrder' + str(i+1)))\n",
    "                    listOfOrders.append(eval('evenOrder' + str(i+1)))\n",
    "\n",
    "                    \n",
    "                    chosenOrder = listOfOrders[labelsequence-1]\n",
    "\n",
    "\n",
    "                # # Number that is used to take the label (oddOrder1 atau evenOrder1)\n",
    "                # i_label_taker = 0\n",
    "\n",
    "                # if i % 2 == 0:\n",
    "\n",
    "                #     # Even number\n",
    "                #     i_label_taker = 0\n",
    "\n",
    "                # else:\n",
    "\n",
    "                #     # Odd number\n",
    "                #     i_label_taker = 1\n",
    "                \n",
    "                # chosenOrder = listOfOrders[i_label_taker]\n",
    "\n",
    "                # Populate all orders\n",
    "                listOfOrders = []\n",
    "                for i in tqdm(range(6)):\n",
    "                    listOfOrders.append(eval('oddOrder' + str(i+1)))\n",
    "                    listOfOrders.append(eval('evenOrder' + str(i+1)))\n",
    "\n",
    "                \n",
    "                chosenOrder = listOfOrders[labelsequence-1]\n",
    "\n",
    "                # Get the first 12 markers' indices and extract the data\n",
    "                indicesofBaselineMarkers = indicesOfMarkers[13:]\n",
    "\n",
    "                # Chunk the data based on opening and closing markers \n",
    "                chunkedData = []\n",
    "                for i in range(0, 12, 2):\n",
    "\n",
    "                    chunkedData.append(df.iloc[indicesofBaselineMarkers[i] : indicesofBaselineMarkers[i+1], :])\n",
    "            \n",
    "                # Match pattern EyeTracker-Sx (x = any number)\n",
    "                regex = r\"\\D{10}-S\\d+\"\n",
    "\n",
    "                # Create filename that will be used for each condition. There are 6 conditions. See oddOrder1 or evenOrder1\n",
    "                extracted_file_name_4_baseline = []\n",
    "                for i in chosenOrder:\n",
    "                    extracted_file_name = re.search(regex,fileName)\n",
    "                    extracted_file_name_4_baseline.append(fileName[extracted_file_name.start() : extracted_file_name.end()] + \"-\" + i + \"_raw.csv\")\n",
    "\n",
    "\n",
    "                # Save the chunkedData into a separate csv file\n",
    "                for i, val in tqdm(enumerate(chunkedData), desc = \"Saving process...\"):\n",
    "                    \n",
    "                    # Convert array into dataframe\n",
    "                    df_chunkedData = pd.DataFrame(val)\n",
    "\n",
    "                    # Save dataframe into csv\n",
    "                    os.chdir(path_2_save_baseline_file)\n",
    "                    df_chunkedData.to_csv(extracted_file_name_4_baseline[i],sep= (\",\"))\n",
    "                    \n",
    "\n",
    "print(f\"All experimental files of eye data have been saved in csv format in this path {path_2_save_baseline_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_experiment_eye_data(path_2_csv_files: str,\n",
    "                                path_2_save_experimental_file: str,\n",
    "                                labelsequence: int = 1,\n",
    "                                bad_files: list = []):\n",
    "    \"\"\"\n",
    "    Extract experimental data from raw Eye Tracker file (*.csv) that was obtained from hyperscanning2-redesign experiment \\n\n",
    "\n",
    "    Arguments :\n",
    "        - path_2_csv_files (str) : path to raw Eye tracker file \\n\n",
    "        - path_2_save_experimental_file (str) : path to save extracted experimental file for each condition \\n\n",
    "        - labelsequence (int) : order of pre-defined label sequence, 1 (averted) is default \\n\n",
    "        - bad_files (list) (optional) : file name of raw EyeTracker file, e.g., EyeTracker-S8.csv, that wants to be skipped to process\n",
    "\n",
    "    Return :\n",
    "        Extracted *.csv file for each condition of hand (finger pointing and tracking).\n",
    "        There are 6 files in total for each participant.\n",
    "    \"\"\"\n",
    "\n",
    "    ## Temporary\n",
    "    # path_2_csv_files = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/\"\n",
    "    # path_2_save_experimental_file = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/experimental_eye_data/\"\n",
    "    # labelsequence = 1\n",
    "    # bad_files = []\n",
    "\n",
    "    ###\n",
    "\n",
    "    list_file_names = []\n",
    "    full_path_2_each_file = []\n",
    "\n",
    "    for file in os.listdir(path_2_csv_files):\n",
    "\n",
    "        if file.endswith(\".csv\"):\n",
    "\n",
    "            if (file in bad_files):\n",
    "                # Skip the bad file to be processed\n",
    "                print(f\"Skipped bad file : {file}\")\n",
    "                continue\n",
    "\n",
    "            # Populate all file names only\n",
    "            list_file_names.append(file)\n",
    "            list_file_names.sort()\n",
    "\n",
    "        # Iterate all file names\n",
    "\n",
    "        for i in tqdm(range(len(list_file_names)), desc=\"In progress\"):\n",
    "\n",
    "            try:\n",
    "                labelsequence = int(labelsequence)\n",
    "\n",
    "            except IOError as err_filename:\n",
    "                print(\n",
    "                    \"The format of file name is not correct or file doesn't exist \\nThe format must be 'EEG-Sx.csv' , x=subject number \"\n",
    "                )\n",
    "                raise\n",
    "            except ValueError as err_integer:\n",
    "                print(\"The labelsequence input must be integer : \",\n",
    "                      err_integer)\n",
    "                raise\n",
    "\n",
    "            else:\n",
    "                if labelsequence < 1 or labelsequence > 12:\n",
    "                    print(\n",
    "                        \"The value for labelsequence parameter is out of range. It must be be between 1 and 12\"\n",
    "                    )\n",
    "                    raise IndexError\n",
    "                else:\n",
    "\n",
    "                    # Load the data\n",
    "                    fileName = list_file_names[i]\n",
    "\n",
    "                    # Change to a folder where original CSV files are stored\n",
    "                    os.chdir(path_2_csv_files)\n",
    "\n",
    "                    print(\"Processing file : \" + list_file_names[i])\n",
    "\n",
    "                    # Read each file by using pandas\n",
    "                    df = pd.read_csv(fileName, delimiter=',')\n",
    "\n",
    "                    df['UnixTimeStamp'] = df.UnixTimeStamp.apply(\n",
    "                        lambda x: \"9999999\" if \"BEGIN\" in x else x)\n",
    "                    df['UnixTimeStamp'] = df.UnixTimeStamp.apply(\n",
    "                        lambda x: \"9999999\" if \"END\" in x else x)\n",
    "\n",
    "                    # Turn the UnixTimeStamp column into a list (we need the marker later on)\n",
    "                    markers = df['UnixTimeStamp'].tolist()\n",
    "\n",
    "                    # Convert string value to integer number\n",
    "                    markers = list(map(int, markers))\n",
    "\n",
    "                    #   Find all experimental markers and print them out.\n",
    "                    indicesOfMarkers = [\n",
    "                    ]  # Empty list to contain indices of markers\n",
    "                    for i, c in enumerate(markers):\n",
    "                        if \"9999999\" in str(c):\n",
    "                            indicesOfMarkers.append(i)\n",
    "                    try:\n",
    "                        number_markers = len(indicesOfMarkers)\n",
    "                        if number_markers != 48:  # check if the number of markers = 48\n",
    "                            raise ValueError(\n",
    "                                \"The {} file has incorrect number of markers : {} ! It MUST be 48\"\n",
    "                                .format(fileName, number_markers))\n",
    "                    except ValueError as err_unmatch_markers:\n",
    "                        print(err_unmatch_markers)\n",
    "                        raise\n",
    "\n",
    "                    # Create a list of labels for experimental data.\n",
    "\n",
    "                    # Order = 1 (Averted/Direct/Natural)\n",
    "                    oddOrder1 = [\n",
    "                        \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                        \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                        \"averted_post_right_point\", \"averted_post_left_point\",\n",
    "                        \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                        \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                        \"direct_post_right_point\", \"direct_post_left_point\",\n",
    "                        \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                        \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                        \"natural_post_right_point\", \"natural_post_left_point\"\n",
    "                    ]\n",
    "\n",
    "                    evenOrder1 = [\n",
    "                        \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                        \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                        \"averted_post_left_point\", \"averted_post_right_point\",\n",
    "                        \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                        \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                        \"direct_post_left_point\", \"direct_post_right_point\",\n",
    "                        \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                        \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                        \"natural_post_left_point\", \"natural_post_right_point\"\n",
    "                    ]\n",
    "\n",
    "                    # Order = 2 (Averted/Natural/Direct)\n",
    "                    oddOrder2 = [\n",
    "                        \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                        \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                        \"averted_post_right_point\", \"averted_post_left_point\",\n",
    "                        \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                        \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                        \"natural_post_right_point\", \"natural_post_left_point\",\n",
    "                        \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                        \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                        \"direct_post_right_point\", \"direct_post_left_point\"\n",
    "                    ]\n",
    "\n",
    "                    evenOrder2 = [\n",
    "                        \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                        \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                        \"averted_post_left_point\", \"averted_post_right_point\",\n",
    "                        \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                        \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                        \"natural_post_left_point\", \"natural_post_right_point\",\n",
    "                        \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                        \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                        \"direct_post_left_point\", \"direct_post_right_point\"\n",
    "                    ]\n",
    "\n",
    "                    # Order = 3 (Direct / Natural / Averted)\n",
    "                    oddOrder3 = [\n",
    "                        \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                        \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                        \"direct_post_right_point\", \"direct_post_left_point\",\n",
    "                        \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                        \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                        \"natural_post_right_point\", \"natural_post_left_point\",\n",
    "                        \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                        \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                        \"averted_post_right_point\", \"averted_post_left_point\"\n",
    "                    ]\n",
    "\n",
    "                    evenOrder3 = [\n",
    "                        \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                        \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                        \"direct_post_left_point\", \"direct_post_right_point\",\n",
    "                        \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                        \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                        \"natural_post_left_point\", \"natural_post_right_point\",\n",
    "                        \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                        \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                        \"averted_post_left_point\", \"averted_post_right_point\"\n",
    "                    ]\n",
    "\n",
    "                    # Order = 4 (Direct/Averted/Natural)\n",
    "                    oddOrder4 = [\n",
    "                        \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                        \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                        \"direct_post_right_point\", \"direct_post_left_point\",\n",
    "                        \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                        \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                        \"averted_post_right_point\", \"averted_post_left_point\",\n",
    "                        \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                        \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                        \"natural_post_right_point\", \"natural_post_left_point\"\n",
    "                    ]\n",
    "\n",
    "                    evenOrder4 = [\n",
    "                        \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                        \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                        \"direct_post_left_point\", \"direct_post_right_point\",\n",
    "                        \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                        \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                        \"averted_post_left_point\", \"averted_post_right_point\",\n",
    "                        \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                        \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                        \"natural_post_left_point\", \"natural_post_right_point\"\n",
    "                    ]\n",
    "\n",
    "                    # Order = 5 (Natural/Direct/Averted)\n",
    "                    oddOrder5 = [\n",
    "                        \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                        \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                        \"natural_post_right_point\", \"natural_post_left_point\",\n",
    "                        \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                        \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                        \"direct_post_right_point\", \"direct_post_left_point\",\n",
    "                        \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                        \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                        \"averted_post_right_point\", \"averted_post_left_point\"\n",
    "                    ]\n",
    "\n",
    "                    evenOrder5 = [\n",
    "                        \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                        \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                        \"natural_post_left_point\", \"natural_post_right_point\",\n",
    "                        \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                        \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                        \"direct_post_left_point\", \"direct_post_right_point\",\n",
    "                        \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                        \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                        \"averted_post_left_point\", \"averted_post_right_point\"\n",
    "                    ]\n",
    "\n",
    "                    # Order = 6 (Natural/Averted/Direct)\n",
    "                    oddOrder6 = [\n",
    "                        \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                        \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                        \"natural_post_right_point\", \"natural_post_left_point\",\n",
    "                        \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                        \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                        \"averted_post_right_point\", \"averted_post_left_point\",\n",
    "                        \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                        \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                        \"direct_post_right_point\", \"direct_post_left_point\"\n",
    "                    ]\n",
    "\n",
    "                    evenOrder6 = [\n",
    "                        \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                        \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                        \"natural_post_left_point\", \"natural_post_right_point\",\n",
    "                        \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                        \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                        \"averted_post_left_point\", \"averted_post_right_point\",\n",
    "                        \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                        \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                        \"direct_post_left_point\", \"direct_post_right_point\"\n",
    "                    ]\n",
    "\n",
    "                    # # Put all labels into a list for experimental data\n",
    "                    # listOfOrders = []\n",
    "                    # listOfOrders.append(oddOrder1)\n",
    "                    # listOfOrders.append(evenOrder1)\n",
    "\n",
    "                    # Populate all orders\n",
    "                    listOfOrders = []\n",
    "                    for i in tqdm(range(6)):\n",
    "                        listOfOrders.append(eval('oddOrder' + str(i + 1)))\n",
    "                        listOfOrders.append(eval('evenOrder' + str(i + 1)))\n",
    "\n",
    "                        chosenOrder = listOfOrders[labelsequence - 1]\n",
    "\n",
    "                    # # Number that is used to take the label (oddOrder1 atau evenOrder1)\n",
    "                    # i_label_taker = 0\n",
    "\n",
    "                    # if i % 2 == 0:\n",
    "\n",
    "                    #     # Even number\n",
    "                    #     i_label_taker = 0\n",
    "\n",
    "                    # else:\n",
    "\n",
    "                    #     # Odd number\n",
    "                    #     i_label_taker = 1\n",
    "\n",
    "                    # chosenOrder = listOfOrders[i_label_taker]\n",
    "\n",
    "                    # Populate all orders\n",
    "                    listOfOrders = []\n",
    "                    for i in tqdm(range(6)):\n",
    "                        listOfOrders.append(eval('oddOrder' + str(i + 1)))\n",
    "                        listOfOrders.append(eval('evenOrder' + str(i + 1)))\n",
    "\n",
    "                    chosenOrder = listOfOrders[labelsequence - 1]\n",
    "\n",
    "                    # Get the first 12 markers' indices and extract the data\n",
    "                    indicesofExperimentalMarkers = indicesOfMarkers[13:]\n",
    "\n",
    "                    # Chunk the data based on opening and closing markers\n",
    "                    chunkedData = []\n",
    "                    for i in range(0, 12, 2):\n",
    "\n",
    "                        chunkedData.append(\n",
    "                            df.iloc[indicesofExperimentalMarkers[i]:\n",
    "                                    indicesofExperimentalMarkers[i + 1], :])\n",
    "\n",
    "                    # Match pattern EyeTracker-Sx (x = any number)\n",
    "                    regex = r\"\\D{10}-S\\d+\"\n",
    "\n",
    "                    # Create filename that will be used for each condition. There are 6 conditions. See oddOrder1 or evenOrder1\n",
    "                    extracted_file_name_4_experimental = []\n",
    "                    for i in chosenOrder:\n",
    "                        extracted_file_name = re.search(regex, fileName)\n",
    "                        extracted_file_name_4_experimental.append(\n",
    "                            fileName[extracted_file_name.start(\n",
    "                            ):extracted_file_name.end()] + \"-\" + i +\n",
    "                            \"_raw.csv\")\n",
    "\n",
    "                    # Save the chunkedData into a separate csv file\n",
    "                    for i, val in tqdm(enumerate(chunkedData),\n",
    "                                       desc=\"Saving process...\"):\n",
    "\n",
    "                        # Convert array into dataframe\n",
    "                        df_chunkedData = pd.DataFrame(val)\n",
    "\n",
    "                        # Save dataframe into csv\n",
    "                        os.chdir(path_2_save_experimental_file)\n",
    "                        df_chunkedData.to_csv(\n",
    "                            extracted_file_name_4_experimental[i], sep=(\",\"))\n",
    "\n",
    "    print(\n",
    "        f\"All experimental files of eye data have been saved in csv format in this path {path_2_save_experimental_file}\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function to extract baseline and experimental eye data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/pre-processing\n"
     ]
    }
   ],
   "source": [
    "# Change current working directory so that it can import the module in the cell below\n",
    "# import os\n",
    "# os.chdir(\"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/pre-processing\")\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import extract_eye_tracker_data\n",
    "# path_2_csv_files = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/\"\n",
    "# path_2_save_experimental_file = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/raw_experimental_eye_data/\"\n",
    "# path_2_save_baseline_file = \"/hpc/igum002/codes/Hyperscanning2-redesign/EyeTracker/data/raw_baseline_eye_data/\"\n",
    "\n",
    "# extract_eye_tracker_data.extract_experiment_eye_data(path_2_csv_files, path_2_save_experimental_file)\n",
    "# extract_eye_tracker_data.extract_baseline_eye_data(path_2_csv_files, path_2_save_baseline_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47fc37aba7a737a16a20c27199a7c13238fa88e6b66a32f6f49d540dad6db454"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
