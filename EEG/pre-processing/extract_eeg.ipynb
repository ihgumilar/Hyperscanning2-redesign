{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : /hpc/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 37957.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data have been extracted from : /hpc/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S1.csv\n",
      "/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S1-averted_baseline_raw.fif\n",
      "Writing /hpc/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S1-averted_baseline_raw.fif\n",
      "Closing /hpc/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S1-averted_baseline_raw.fif\n",
      "[done]\n",
      "File has been saved in fif format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#%%\n",
    "# def extract_eeg_data(path_2_csv_files, labelsequence, path_2_save_files)\n",
    "# def extract_eeg_data(filename, labelsequence):\n",
    "filename = \"/hpc/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S1.csv\"\n",
    "labelsequence = 1\n",
    "\n",
    "# List and sort all csv files\n",
    "# TODO Uncomment this loop when we are ready\n",
    "\n",
    "path_2_csv_files = \"/hpc/igum002/codes/Hyperscanning2-redesign/data/EEG\"\n",
    "list_file_names = []\n",
    "full_path_4_each_file = []\n",
    "\n",
    "for (root, dirs, file) in os.walk(path_2_csv_files):\n",
    "    for f in file:\n",
    "        if \".csv\" in f:\n",
    "            # Populate all file names only\n",
    "            list_file_names.append(f)\n",
    "            list_file_names.sort()\n",
    "\n",
    "            # Populate all full paths of each filename\n",
    "            full_path_4_each_file.append(os.path.join(root, f))\n",
    "            full_path_4_each_file.sort()\n",
    "\n",
    "try:\n",
    "    f = open(filename)\n",
    "    labelsequence = int(labelsequence)\n",
    "\n",
    "except IOError as err_filename:\n",
    "    print(\"The format of file name is not correct or file doesn't exist \\nThe format must be 'EEG-Sx.csv' , x=subject number \")\n",
    "    raise\n",
    "except ValueError as err_integer:\n",
    "    print(\"The labelsequence input must be integer : \", err_integer)\n",
    "    raise\n",
    "\n",
    "else:\n",
    "    if  labelsequence < 1 or labelsequence > 12:\n",
    "        print(\"The value for labelsequence parameter is out of range. It must be be between 1 and 12\")\n",
    "        raise IndexError\n",
    "    else:\n",
    "\n",
    "        #%% Load the data\n",
    "        fileName = filename  # The format of file name of EEG must be like this\n",
    "        print(\"Processing file : \" + fileName)\n",
    "        df = pd.read_csv(fileName, delimiter=',')\n",
    "        # %% Define columns for raw csv file\n",
    "        df.columns = ['Index', 'FP1', 'FP2', 'F7', 'F3', 'F4', 'F8', 'T7', 'C3', 'C4', 'T8', 'P7', 'P3', 'P4', 'P8', 'O1',\n",
    "                        'O2', 'X1', 'X2', 'X3', 'X4', 'X5',\n",
    "                        'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'Marker']\n",
    "        # Converting all markers (pandas data frame to list)\n",
    "        markers = df['Marker'].tolist()\n",
    "        # %%  Find all experimental markers and print them out.\n",
    "\n",
    "        indicesOfMarkers = []  # Empty list to contain indices of markers\n",
    "        for i, c in enumerate(markers):\n",
    "            if \"9999999\" in str(c) : \n",
    "                indicesOfMarkers.append(i) \n",
    "        try:\n",
    "            number_markers = len(indicesOfMarkers)\n",
    "            if number_markers != 48:   # check if the number of markers = 48\n",
    "                raise ValueError(\"The {} file has incorrect number of markers : {} ! It MUST be 48\".format(fileName,number_markers))\n",
    "        except ValueError as err_unmatch_markers:\n",
    "            print(err_unmatch_markers)\n",
    "            raise\n",
    "\n",
    "\n",
    "        # %% Loop the list of labels in sequence\n",
    "        # todo Create a list of labels with different sequences and put them into a list (list of list)\n",
    "        # Order = 1 (Averted/Direct/Natural)\n",
    "        oddOrder1 = [\"averted_pre_right_point\", \"averted_pre_left_point\", \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                        \"averted_post_right_point\", \"averted_post_left_point\", \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                        \"direct_left_tracking\", \"direct_right_tracking\", \"direct_post_right_point\", \"direct_post_left_point\",\n",
    "                        \"natural_pre_right_point\", \"natural_pre_left_point\", \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                        \"natural_post_right_point\", \"natural_post_left_point\"]\n",
    "\n",
    "        evenOrder1 = [\"averted_pre_left_point\", \"averted_pre_right_point\", \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                        \"averted_post_left_point\", \"averted_post_right_point\", \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                        \"direct_right_tracking\", \"direct_left_tracking\", \"direct_post_left_point\", \"direct_post_right_point\",\n",
    "                        \"natural_pre_left_point\", \"natural_pre_right_point\", \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                        \"natural_post_left_point\", \"natural_post_right_point\"]\n",
    "\n",
    "        # Order = 2 (Averted/Natural/Direct)\n",
    "        oddOrder2 = [\"averted_pre_right_point\", \"averted_pre_left_point\", \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                        \"averted_post_right_point\", \"averted_post_left_point\", \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                        \"natural_left_tracking\", \"natural_right_tracking\", \"natural_post_right_point\", \"natural_post_left_point\",\n",
    "                        \"direct_pre_right_point\", \"direct_pre_left_point\", \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                        \"direct_post_right_point\", \"direct_post_left_point\"]\n",
    "\n",
    "        evenOrder2 = [\"averted_pre_left_point\", \"averted_pre_right_point\", \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                        \"averted_post_left_point\", \"averted_post_right_point\", \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                        \"natural_right_tracking\", \"natural_left_tracking\", \"natural_post_left_point\", \"natural_post_right_point\",\n",
    "                        \"direct_pre_left_point\", \"direct_pre_right_point\", \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                        \"direct_post_left_point\", \"direct_post_right_point\"]\n",
    "\n",
    "        # Order = 3 (Direct / Natural / Averted)\n",
    "        oddOrder3 = [\"direct_pre_right_point\", \"direct_pre_left_point\", \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                        \"direct_post_right_point\", \"direct_post_left_point\", \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                        \"natural_left_tracking\", \"natural_right_tracking\", \"natural_post_right_point\", \"natural_post_left_point\",\n",
    "                        \"averted_pre_right_point\", \"averted_pre_left_point\", \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                        \"averted_post_right_point\", \"averted_post_left_point\"]\n",
    "\n",
    "        evenOrder3 = [\"direct_pre_left_point\", \"direct_pre_right_point\", \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                        \"direct_post_left_point\", \"direct_post_right_point\", \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                        \"natural_right_tracking\", \"natural_left_tracking\", \"natural_post_left_point\", \"natural_post_right_point\",\n",
    "                        \"averted_pre_left_point\", \"averted_pre_right_point\", \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                        \"averted_post_left_point\", \"averted_post_right_point\"]\n",
    "\n",
    "        # Order = 4 (Direct/Averted/Natural)\n",
    "        oddOrder4 = [\"direct_pre_right_point\", \"direct_pre_left_point\", \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                        \"direct_post_right_point\", \"direct_post_left_point\", \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                        \"averted_left_tracking\", \"averted_right_tracking\", \"averted_post_right_point\", \"averted_post_left_point\",\n",
    "                        \"natural_pre_right_point\", \"natural_pre_left_point\", \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                        \"natural_post_right_point\", \"natural_post_left_point\"]\n",
    "\n",
    "        evenOrder4 = [\"direct_pre_left_point\", \"direct_pre_right_point\", \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                        \"direct_post_left_point\", \"direct_post_right_point\", \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                        \"averted_right_tracking\", \"averted_left_tracking\", \"averted_post_left_point\", \"averted_post_right_point\",\n",
    "                        \"natural_pre_left_point\", \"natural_pre_right_point\", \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                        \"natural_post_left_point\", \"natural_post_right_point\"]\n",
    "\n",
    "        # Order = 5 (Natural/Direct/Averted)\n",
    "        oddOrder5 = [\"natural_pre_right_point\", \"natural_pre_left_point\", \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                        \"natural_post_right_point\", \"natural_post_left_point\", \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                        \"direct_left_tracking\", \"direct_right_tracking\", \"direct_post_right_point\", \"direct_post_left_point\",\n",
    "                        \"averted_pre_right_point\", \"averted_pre_left_point\", \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                        \"averted_post_right_point\", \"averted_post_left_point\"]\n",
    "\n",
    "        evenOrder5 = [\"natural_pre_left_point\", \"natural_pre_right_point\", \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                        \"natural_post_left_point\", \"natural_post_right_point\", \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                        \"direct_right_tracking\", \"direct_left_tracking\", \"direct_post_left_point\", \"direct_post_right_point\",\n",
    "                        \"averted_pre_left_point\", \"averted_pre_right_point\", \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                        \"averted_post_left_point\", \"averted_post_right_point\"]\n",
    "\n",
    "        # Order = 6 (Natural/Averted/Direct)\n",
    "        oddOrder6 = [\"natural_pre_right_point\", \"natural_pre_left_point\", \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                        \"natural_post_right_point\", \"natural_post_left_point\", \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                        \"averted_left_tracking\", \"averted_right_tracking\", \"averted_post_right_point\", \"averted_post_left_point\",\n",
    "                        \"direct_pre_right_point\", \"direct_pre_left_point\", \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                        \"direct_post_right_point\", \"direct_post_left_point\"]\n",
    "\n",
    "        evenOrder6 = [\"natural_pre_left_point\", \"natural_pre_right_point\", \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                        \"natural_post_left_point\", \"natural_post_right_point\", \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                        \"averted_right_tracking\", \"averted_left_tracking\", \"averted_post_left_point\", \"averted_post_right_point\",\n",
    "                        \"direct_pre_left_point\", \"direct_pre_right_point\", \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                        \"direct_post_left_point\", \"direct_post_right_point\"]\n",
    "        #%% Add all labels into a list\n",
    "\n",
    "        listOfOrders = []\n",
    "        for i in tqdm(range(6)):\n",
    "            listOfOrders.append(eval('oddOrder' + str(i+1)))\n",
    "            listOfOrders.append(eval('evenOrder' + str(i+1)))\n",
    "        print(\"Data have been extracted from : \" + fileName)\n",
    "        chosenOrder = listOfOrders[labelsequence-1]\n",
    "\n",
    "        # BASELINE DATA\n",
    "\n",
    "        # %% Get the first 12 markers' indices and extract the data\n",
    "        indicesofBaselineMarkers = indicesOfMarkers[:13]\n",
    "\n",
    "        # Get the 1st and 12th index and chunk dataframe based on those indices, and convert it into numpy array\n",
    "        # For some data, it can be 13 markers after being extracted because when we combined the data the markers of beginning are right after the closing marker\n",
    "\n",
    "        # baseline_data = []\n",
    "        baseline_data = df.iloc[indicesofBaselineMarkers[0] : indicesofBaselineMarkers[-1], 1:17].to_numpy() * 1e-6\n",
    "        \n",
    "        # %% Load each baseline file into MNE Python (averted eye condition only for baseline)\n",
    "\n",
    "        # Create 16 channels montage 10-20 international standard\n",
    "        montage = mne.channels.make_standard_montage('standard_1020')\n",
    "\n",
    "        # Pick only 16 channels that are used in Cyton+Daisy OpenBCI\n",
    "         # % Create info\n",
    "        ch_names = ['FP1', 'Fp2', 'F7', 'F3', 'F4', 'F8', 'T7', 'C3', 'C4', 'T8', 'P7', 'P3', 'P4', 'P8', 'O1', 'O2']\n",
    "        ch_types = ['eeg'] * 16\n",
    "        info = mne.create_info(\n",
    "            ch_names=ch_names,\n",
    "            sfreq=125,\n",
    "            ch_types=ch_types)\n",
    "        info.set_montage('standard_1020', match_case=False)\n",
    "      \n",
    "               \n",
    "        # Save the baseline data into .fif file \n",
    "        # for i, val in enumerate(baseline_data):\n",
    "\n",
    "        # baseline_data_needs_label = mne.io.RawArray(val.transpose(), info, verbose=False)\n",
    "        # baseline_data_needs_label.save(join(filenames_fif[i]), overwrite=True)\n",
    "\n",
    "        # Load data into MNE-Python\n",
    "        baseline_data_needs_label = mne.io.RawArray(baseline_data.transpose(), info, verbose=False)\n",
    "\n",
    "        # Define a folder where we want to save the baseline data\n",
    "        os.chdir(\"/hpc/igum002/codes/Hyperscanning2-redesign/data/EEG/\")  # Input folder path to save baseline data\n",
    "       \n",
    "        # Match pattern EEG-Sx (x = any number)\n",
    "        regex = r\"\\D{3}-S\\d+\"\n",
    "\n",
    "        # Find characters (file name) that matches the regex\n",
    "        extracted_file_name = re.search(regex,fileName)\n",
    "        extracted_file_name_4_baseline = fileName[extracted_file_name.start() : extracted_file_name.end()] + \"-\" + \"averted_baseline\" + \"_raw.fif\"\n",
    "\n",
    "\n",
    "        # Save the data in MNE format\n",
    "        baseline_data_needs_label.save(extracted_file_name_4_baseline, overwrite=True)\n",
    "        print(\"File has been saved in fif format\")\n",
    "\n",
    "        \n",
    "        # TODO search files of csv in folder so that we need to input folder that contains csv files\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ############### EXPERIMENTAL DATA ##################\n",
    "\n",
    "        # # %% Chunk the data based on opening and closing markers and get only the 16 channels data (columns)\n",
    "        # chunkedData = []\n",
    "        # for i in range(0, 36, 2):\n",
    "        #     # averted_pre_right_point = df.iloc[indicesOfMarkers[0] : indicesOfMarkers[1] +1, 1:17]\n",
    "        #     # Change into numpy and convert it from uV (microvolts) / nV to V (volts)\n",
    "        #     chunkedData.append(df.iloc[indicesOfMarkers[i]: indicesOfMarkers[i + 1] + 1, 1:17].to_numpy() * 1e-6)\n",
    "        # # %% Load each eye condition file into MNE Python\n",
    "        # # Create 16 channels montage 10-20 international standard\n",
    "        # montage = mne.channels.make_standard_montage('standard_1020')\n",
    "        # # Pick only 16 channels that are used in Cyton+Daisy OpenBCI\n",
    "        # # % Create info\n",
    "        # ch_names = ['FP1', 'Fp2', 'F7', 'F3', 'F4', 'F8', 'T7', 'C3', 'C4', 'T8', 'P7', 'P3', 'P4', 'P8', 'O1', 'O2']\n",
    "        # ch_types = ['eeg'] * 16\n",
    "        # info = mne.create_info(\n",
    "        #     ch_names=ch_names,\n",
    "        #     sfreq=125,\n",
    "        #     ch_types=ch_types)\n",
    "        # info.set_montage('standard_1020', match_case=False)\n",
    "        # # %% Create filenames for *.fif based on the sequence of labels above\n",
    "        # filenames_fif = []\n",
    "        # for i in chosenOrder:\n",
    "        #     filenames_fif.append(fileName[4:fileName.index(\".\")] + \"-\" + i + \"_raw.fif\")\n",
    "        # #%% Save into *.fif files\n",
    "        # for i, val in enumerate(chunkedData):\n",
    "        #     data_need_label = mne.io.RawArray(val.transpose(), info, verbose=False)\n",
    "        #     data_need_label.save(join(filenames_fif[i]), overwrite=True)\n",
    "        # # TODO save it into MNE-BIDS format\n",
    "\n",
    "\n",
    "\n",
    "        # # extract_eeg_data(\"EEG-S10.csv\", 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EEG-S1.csv', 'EEG-S2.csv', 'EEG-S3.csv', 'EEG-S4.csv', 'EEG-S5.csv', 'EEG-S6.csv', 'EEG-S7.csv', 'EEG-S8.csv']\n",
      "['/hpc/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S1.csv', '/hpc/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S2.csv', '/hpc/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S3.csv', '/hpc/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S4.csv', '/hpc/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S5.csv', '/hpc/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S6.csv', '/hpc/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S7.csv', '/hpc/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S8.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path_2_csv_files = \"/hpc/igum002/codes/Hyperscanning2-redesign/data/EEG\"\n",
    "list_file_names = []\n",
    "full_path_4_each_file = []\n",
    "for (root, dirs, file) in os.walk(path_2_csv_files):\n",
    "    for f in file:\n",
    "        if \".csv\" in f:\n",
    "            # Populate all file names only\n",
    "            list_file_names.append(f)\n",
    "            list_file_names.sort()\n",
    "\n",
    "            # Populate all full path of filenames\n",
    "            full_path_4_each_file.append(os.path.join(root, f))\n",
    "            full_path_4_each_file.sort()\n",
    "\n",
    "    print(list_file_names)\n",
    "    print(full_path_4_each_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EEG-S1.csv',\n",
       " 'EEG-S2.csv',\n",
       " 'EEG-S3.csv',\n",
       " 'EEG-S4.csv',\n",
       " 'EEG-S5.csv',\n",
       " 'EEG-S6.csv',\n",
       " 'EEG-S7.csv',\n",
       " 'EEG-S8.csv']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_file_names.sort()\n",
    "list_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S10-averted_baseline_raw.fif\n",
      "<re.Match object; span=(48, 55), match='EEG-S10'>\n",
      "Start index :  48\n",
      "End index :  55\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# stringA = filenames_fif_baseline[0]\n",
    "stringA = \"/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S10-averted_baseline_raw.fif\"\n",
    "print(stringA)\n",
    "\n",
    "# Match pattern EEG-Sx (x = any number)\n",
    "regex = r\"\\D{3}-S\\d+\"\n",
    "\n",
    "\n",
    "test_file_name = re.search(regex,stringA)\n",
    "print(test_file_name)\n",
    "print(\"Start index : \", test_file_name.start())\n",
    "print(\"End index : \", test_file_name.end())\n",
    "print(type(stringA[test_file_name.start():test_file_name.end()]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work in progress saving into file name (success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/igum002/codes/Hyperscanning2-redesign/data/EEG/EEG-S1-averted_baseline_raw.fif\n"
     ]
    }
   ],
   "source": [
    "print(filenames_fif_baseline[0]) # Recheck the file name\n",
    "# baseline_data_needs_label.save(\"baseline_test_saving_raw.fif\", overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Get the first 12 markers' indices and extract the data\n",
    "indicesofBaselineMarkers = indicesOfMarkers[:13]\n",
    "\n",
    "# Get the 1st and 13th index and chunk dataframe based on those indices, and convert it into numpy array\n",
    "baseline_data = df.iloc[indicesofBaselineMarkers[0] : indicesofBaselineMarkers[-1], 1:17].to_numpy() * 1e-6\n",
    "\n",
    " # Save the baseline data into .fif file \n",
    "# baseline_data = \n",
    "\n",
    "# _(Ensure there are 12 markers in the baseline_data )\n",
    "\n",
    "# Save the data into .fif file \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Checking there are 12 / 13 markers in baseline data because marker is closed for some files. Right after one another between end and opening marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "[0, 7075, 7916, 15335, 16428, 23979, 24692, 32234, 32881, 40382, 41043, 48516]\n"
     ]
    }
   ],
   "source": [
    "# Converting all markers (pandas data frame to list)\n",
    "markers_bl = baseline_df['Marker'].tolist()\n",
    "# %%  Find all experimental markers and print them out.\n",
    "\n",
    "indicesOfMarkers_bl = []  # Empty list to contain indices of markers\n",
    "for i, c in enumerate(markers_bl):\n",
    "    if \"9999999\" in str(c) : #todo untuk data EEG-S1-6.csv, tambahkan \" : \"\n",
    "        indicesOfMarkers_bl.append(i) # check if the number of markers = 36\n",
    "print(len(indicesOfMarkers_bl))\n",
    "print(indicesOfMarkers_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = df.iloc[indicesofBaselineMarkers[0] : indicesofBaselineMarkers[-1] + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORIGINAL SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#%%\n",
    "def extract_eeg_data(filename, labelsequence):\n",
    "    try:\n",
    "        f = open(filename)\n",
    "        labelsequence = int(labelsequence)\n",
    "\n",
    "    except IOError as err_filename:\n",
    "        print(\"The format of file name is not correct or file doesn't exist \\nThe format must be 'EEG-Sx.csv' , x=subject number \")\n",
    "        raise\n",
    "    except ValueError as err_integer:\n",
    "        print(\"The labelsequence input must be integer : \", err_integer)\n",
    "        raise\n",
    "\n",
    "    else:\n",
    "        if  labelsequence < 1 or labelsequence > 12:\n",
    "            print(\"The value for labelsequence parameter is out of range. It must be be between 1 and 12\")\n",
    "            raise IndexError\n",
    "        else:\n",
    "\n",
    "            #%% Load the data\n",
    "            # filename = \"EEG-S1.csv\"\n",
    "            fileName = filename  # The format of file name of EEG must be like this\n",
    "            print(\"Processing file : \" + fileName)\n",
    "            df = pd.read_csv(fileName, delimiter=',')\n",
    "            # %% Define columns for raw csv file\n",
    "            df.columns = ['Index', 'FP1', 'FP2', 'F7', 'F3', 'F4', 'F8', 'T7', 'C3', 'C4', 'T8', 'P7', 'P3', 'P4', 'P8', 'O1',\n",
    "                          'O2', 'X1', 'X2', 'X3', 'X4', 'X5',\n",
    "                          'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'Marker']\n",
    "            # Converting all markers (pandas data frame to list)\n",
    "            markers = df['Marker'].tolist()\n",
    "            # %%  Find all experimental markers and print them out.\n",
    "\n",
    "            indicesOfMarkers = []  # Empty list to contain indices of markers\n",
    "            for i, c in enumerate(markers):\n",
    "                if \"9999999\" in str(c) : #todo untuk data EEG-S1-6.csv, tambahkan \" : \"\n",
    "                    indicesOfMarkers.append(i) # check if the number of markers = 36\n",
    "            try:\n",
    "                number_markers = len(indicesOfMarkers)\n",
    "                if number_markers != 48:\n",
    "                    raise ValueError(\"The {} file has incorrect number of markers : {} ! It MUST be 36\".format(fileName,number_markers))\n",
    "            except ValueError as err_unmatch_markers:\n",
    "                print(err_unmatch_markers)\n",
    "                raise\n",
    "\n",
    "\n",
    "            # %% Loop the list of labels in sequence\n",
    "            # todo Create a list of labels with different sequences and put them into a list (list of list)\n",
    "            # Order = 1 (Averted/Direct/Natural)\n",
    "            oddOrder1 = [\"averted_pre_right_point\", \"averted_pre_left_point\", \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                         \"averted_post_right_point\", \"averted_post_left_point\", \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                         \"direct_left_tracking\", \"direct_right_tracking\", \"direct_post_right_point\", \"direct_post_left_point\",\n",
    "                         \"natural_pre_right_point\", \"natural_pre_left_point\", \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                         \"natural_post_right_point\", \"natural_post_left_point\"]\n",
    "\n",
    "            evenOrder1 = [\"averted_pre_left_point\", \"averted_pre_right_point\", \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                          \"averted_post_left_point\", \"averted_post_right_point\", \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                          \"direct_right_tracking\", \"direct_left_tracking\", \"direct_post_left_point\", \"direct_post_right_point\",\n",
    "                          \"natural_pre_left_point\", \"natural_pre_right_point\", \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                          \"natural_post_left_point\", \"natural_post_right_point\"]\n",
    "\n",
    "            # Order = 2 (Averted/Natural/Direct)\n",
    "            oddOrder2 = [\"averted_pre_right_point\", \"averted_pre_left_point\", \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                         \"averted_post_right_point\", \"averted_post_left_point\", \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                         \"natural_left_tracking\", \"natural_right_tracking\", \"natural_post_right_point\", \"natural_post_left_point\",\n",
    "                         \"direct_pre_right_point\", \"direct_pre_left_point\", \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                         \"direct_post_right_point\", \"direct_post_left_point\"]\n",
    "\n",
    "            evenOrder2 = [\"averted_pre_left_point\", \"averted_pre_right_point\", \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                          \"averted_post_left_point\", \"averted_post_right_point\", \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                          \"natural_right_tracking\", \"natural_left_tracking\", \"natural_post_left_point\", \"natural_post_right_point\",\n",
    "                          \"direct_pre_left_point\", \"direct_pre_right_point\", \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                          \"direct_post_left_point\", \"direct_post_right_point\"]\n",
    "\n",
    "            # Order = 3 (Direct / Natural / Averted)\n",
    "            oddOrder3 = [\"direct_pre_right_point\", \"direct_pre_left_point\", \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                         \"direct_post_right_point\", \"direct_post_left_point\", \"natural_pre_right_point\", \"natural_pre_left_point\",\n",
    "                         \"natural_left_tracking\", \"natural_right_tracking\", \"natural_post_right_point\", \"natural_post_left_point\",\n",
    "                         \"averted_pre_right_point\", \"averted_pre_left_point\", \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                         \"averted_post_right_point\", \"averted_post_left_point\"]\n",
    "\n",
    "            evenOrder3 = [\"direct_pre_left_point\", \"direct_pre_right_point\", \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                          \"direct_post_left_point\", \"direct_post_right_point\", \"natural_pre_left_point\", \"natural_pre_right_point\",\n",
    "                          \"natural_right_tracking\", \"natural_left_tracking\", \"natural_post_left_point\", \"natural_post_right_point\",\n",
    "                          \"averted_pre_left_point\", \"averted_pre_right_point\", \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                          \"averted_post_left_point\", \"averted_post_right_point\"]\n",
    "\n",
    "            # Order = 4 (Direct/Averted/Natural)\n",
    "            oddOrder4 = [\"direct_pre_right_point\", \"direct_pre_left_point\", \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                         \"direct_post_right_point\", \"direct_post_left_point\", \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                         \"averted_left_tracking\", \"averted_right_tracking\", \"averted_post_right_point\", \"averted_post_left_point\",\n",
    "                         \"natural_pre_right_point\", \"natural_pre_left_point\", \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                         \"natural_post_right_point\", \"natural_post_left_point\"]\n",
    "\n",
    "            evenOrder4 = [\"direct_pre_left_point\", \"direct_pre_right_point\", \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                          \"direct_post_left_point\", \"direct_post_right_point\", \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                          \"averted_right_tracking\", \"averted_left_tracking\", \"averted_post_left_point\", \"averted_post_right_point\",\n",
    "                          \"natural_pre_left_point\", \"natural_pre_right_point\", \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                          \"natural_post_left_point\", \"natural_post_right_point\"]\n",
    "\n",
    "            # Order = 5 (Natural/Direct/Averted)\n",
    "            oddOrder5 = [\"natural_pre_right_point\", \"natural_pre_left_point\", \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                         \"natural_post_right_point\", \"natural_post_left_point\", \"direct_pre_right_point\", \"direct_pre_left_point\",\n",
    "                         \"direct_left_tracking\", \"direct_right_tracking\", \"direct_post_right_point\", \"direct_post_left_point\",\n",
    "                         \"averted_pre_right_point\", \"averted_pre_left_point\", \"averted_left_tracking\", \"averted_right_tracking\",\n",
    "                         \"averted_post_right_point\", \"averted_post_left_point\"]\n",
    "\n",
    "            evenOrder5 = [\"natural_pre_left_point\", \"natural_pre_right_point\", \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                          \"natural_post_left_point\", \"natural_post_right_point\", \"direct_pre_left_point\", \"direct_pre_right_point\",\n",
    "                          \"direct_right_tracking\", \"direct_left_tracking\", \"direct_post_left_point\", \"direct_post_right_point\",\n",
    "                          \"averted_pre_left_point\", \"averted_pre_right_point\", \"averted_right_tracking\", \"averted_left_tracking\",\n",
    "                          \"averted_post_left_point\", \"averted_post_right_point\"]\n",
    "\n",
    "            # Order = 6 (Natural/Averted/Direct)\n",
    "            oddOrder6 = [\"natural_pre_right_point\", \"natural_pre_left_point\", \"natural_left_tracking\", \"natural_right_tracking\",\n",
    "                         \"natural_post_right_point\", \"natural_post_left_point\", \"averted_pre_right_point\", \"averted_pre_left_point\",\n",
    "                         \"averted_left_tracking\", \"averted_right_tracking\", \"averted_post_right_point\", \"averted_post_left_point\",\n",
    "                         \"direct_pre_right_point\", \"direct_pre_left_point\", \"direct_left_tracking\", \"direct_right_tracking\",\n",
    "                         \"direct_post_right_point\", \"direct_post_left_point\"]\n",
    "\n",
    "            evenOrder6 = [\"natural_pre_left_point\", \"natural_pre_right_point\", \"natural_right_tracking\", \"natural_left_tracking\",\n",
    "                          \"natural_post_left_point\", \"natural_post_right_point\", \"averted_pre_left_point\", \"averted_pre_right_point\",\n",
    "                          \"averted_right_tracking\", \"averted_left_tracking\", \"averted_post_left_point\", \"averted_post_right_point\",\n",
    "                          \"direct_pre_left_point\", \"direct_pre_right_point\", \"direct_right_tracking\", \"direct_left_tracking\",\n",
    "                          \"direct_post_left_point\", \"direct_post_right_point\"]\n",
    "            #%% Add all labels into a list\n",
    "\n",
    "            listOfOrders = []\n",
    "            for i in progressbar(range(6)):\n",
    "                listOfOrders.append(eval('oddOrder' + str(i+1)))\n",
    "                listOfOrders.append(eval('evenOrder' + str(i+1)))\n",
    "            print(\"Data have been extracted from : \" + fileName)\n",
    "            chosenOrder = listOfOrders[labelsequence-1]\n",
    "            # %% Chunk the data based on opening and closing markers and get only the 16 channels data (columns)\n",
    "            chunkedData = []\n",
    "            for i in range(0, 36, 2):\n",
    "                # averted_pre_right_point = df.iloc[indicesOfMarkers[0] : indicesOfMarkers[1] +1, 1:17]\n",
    "                # Change into numpy and convert it from uV (microvolts) / nV to V (volts)\n",
    "                chunkedData.append(df.iloc[indicesOfMarkers[i]: indicesOfMarkers[i + 1] + 1, 1:17].to_numpy() * 1e-6)\n",
    "            # %% Load each eye condition file into MNE Python\n",
    "            # Create 16 channels montage 10-20 international standard\n",
    "            montage = mne.channels.make_standard_montage('standard_1020')\n",
    "            # % Create info\n",
    "            # Pick only 16 channels that are used in Cyton+Daisy OpenBCI\n",
    "            ch_names = ['FP1', 'Fp2', 'F7', 'F3', 'F4', 'F8', 'T7', 'C3', 'C4', 'T8', 'P7', 'P3', 'P4', 'P8', 'O1', 'O2']\n",
    "            ch_types = ['eeg'] * 16\n",
    "            info = mne.create_info(\n",
    "                ch_names=ch_names,\n",
    "                sfreq=125,\n",
    "                ch_types=ch_types)\n",
    "            info.set_montage('standard_1020', match_case=False)\n",
    "            # %% Create filenames for *.fif based on the sequence of labels above\n",
    "            filenames_fif = []\n",
    "            for i in chosenOrder:\n",
    "                filenames_fif.append(fileName[4:fileName.index(\".\")] + \"-\" + i + \"_raw.fif\")\n",
    "            #%% Save into *.fif files\n",
    "            for i, val in enumerate(chunkedData):\n",
    "                data_need_label = mne.io.RawArray(val.transpose(), info, verbose=False)\n",
    "                data_need_label.save(join(filenames_fif[i]), overwrite=True)\n",
    "            # todo save it into MNE-BIDS format\n",
    "\n",
    "\n",
    "\n",
    "# extract_eeg_data(\"EEG-S10.csv\", 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('hyperscanning2_redesign_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "096a9cfb5dd708673d7bad520942c5652bd477bd1f0d767668ab378a8c2877fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
